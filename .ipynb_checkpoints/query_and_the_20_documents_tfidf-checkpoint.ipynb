{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "filename = 'documents/document_1.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "#print (text)\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "w = list(filter(None,stripped))\n",
    "#print(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3477"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "freq_dis={}\n",
    "for tok in w:\n",
    "    if tok in freq_dis:\n",
    "        freq_dis[tok] += 1\n",
    "    else:\n",
    "        freq_dis[tok] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_freq_dist= sorted(freq_dis.items(), key=operator.itemgetter(1),\n",
    "reverse=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  the  273"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1=pd.DataFrame(sorted_freq_dist)\n",
    "doc1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3477"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1[1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1.rename(columns={doc1.columns[0]: \"doc1\", doc1.columns[1]: \"feq_doc1\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc1</th>\n",
       "      <th>feq_doc1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc1  feq_doc1\n",
       "0  the       273"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  load data\n",
    "filename = 'documents/document_2.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "#print (text)\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "\n",
    "f = list(filter(None,stripped))\n",
    "#print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "freq_dis={}\n",
    "for tok in f:\n",
    "    if tok in freq_dis:\n",
    "        freq_dis[tok] += 1\n",
    "    else:\n",
    "        freq_dis[tok] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_freq_dist= sorted(freq_dis.items(), key=operator.itemgetter(1),\n",
    "reverse=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  the  322"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2 =pd.DataFrame(sorted_freq_dist)\n",
    "doc2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2.rename(columns={doc2.columns[0]: \"doc2\", doc2.columns[1]: \"feq_doc2\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc2</th>\n",
       "      <th>feq_doc2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc2  feq_doc2\n",
       "0  the       322"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  load data\n",
    "filename = 'documents/document_3.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "#print (text)\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "\n",
    "l = list(filter(None,stripped))\n",
    "#print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "freq_dis={}\n",
    "for tok in l:\n",
    "    if tok in freq_dis:\n",
    "        freq_dis[tok] += 1\n",
    "    else:\n",
    "        freq_dis[tok] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_freq_dist= sorted(freq_dis.items(), key=operator.itemgetter(1),\n",
    "reverse=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1\n",
       "0  the  25"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc3=pd.DataFrame(sorted_freq_dist)\n",
    "doc3.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3.rename(columns={doc3.columns[0]: \"doc3\", doc3.columns[1]: \"feq_doc3\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc3</th>\n",
       "      <th>feq_doc3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc3  feq_doc3\n",
       "0  the        25"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc3.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "filename = 'documents/document_4.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "#print (text)\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "\n",
    "m = list(filter(None,stripped))\n",
    "#print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "freq_dis={}\n",
    "for tok in l:\n",
    "    if tok in freq_dis:\n",
    "        freq_dis[tok] += 1\n",
    "    else:\n",
    "        freq_dis[tok] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_freq_dist= sorted(freq_dis.items(), key=operator.itemgetter(1),\n",
    "reverse=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1\n",
       "0  the  25"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc4=pd.DataFrame(sorted_freq_dist)\n",
    "doc4.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4.rename(columns={doc4.columns[0]: \"doc4\", doc4.columns[1]: \"feq_doc4\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc4</th>\n",
       "      <th>feq_doc4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc4  feq_doc4\n",
       "0  the        25"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc4.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "filename = 'documents/document_5.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "#print (text)\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "\n",
    "n = list(filter(None,stripped))\n",
    "#print(w)\n",
    "\n",
    "import operator\n",
    "freq_dis={}\n",
    "for tok in n:\n",
    "    if tok in freq_dis:\n",
    "        freq_dis[tok] += 1\n",
    "    else:\n",
    "        freq_dis[tok] = 1\n",
    "\n",
    "sorted_freq_dist= sorted(freq_dis.items(), key=operator.itemgetter(1),\n",
    "reverse=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  the  612"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc5=pd.DataFrame(sorted_freq_dist)\n",
    "doc5.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc5.rename(columns={doc5.columns[0]: \"doc5\", doc5.columns[1]: \"feq_doc5\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc5</th>\n",
       "      <th>feq_doc5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc5  feq_doc5\n",
       "0  the       612"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc5.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  the  407"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "filename = 'documents/document_6.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "#print (text)\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "\n",
    "o = list(filter(None,stripped))\n",
    "#print(w)\n",
    "\n",
    "import operator\n",
    "freq_dis={}\n",
    "for tok in o:\n",
    "    if tok in freq_dis:\n",
    "        freq_dis[tok] += 1\n",
    "    else:\n",
    "        freq_dis[tok] = 1\n",
    "\n",
    "sorted_freq_dist= sorted(freq_dis.items(), key=operator.itemgetter(1),\n",
    "reverse=True)\n",
    "\n",
    "\n",
    "\n",
    "doc6=pd.DataFrame(sorted_freq_dist)\n",
    "doc6.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc6</th>\n",
       "      <th>feq_doc6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc6  feq_doc6\n",
       "0  the       407"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc6.rename(columns={doc6.columns[0]: \"doc6\", doc6.columns[1]: \"feq_doc6\"}, inplace=True)\n",
    "\n",
    "doc6.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  the  266"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "filename = 'documents/document_7.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "#print (text)\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "\n",
    "p = list(filter(None,stripped))\n",
    "#print(w)\n",
    "\n",
    "import operator\n",
    "freq_dis={}\n",
    "for tok in p:\n",
    "    if tok in freq_dis:\n",
    "        freq_dis[tok] += 1\n",
    "    else:\n",
    "        freq_dis[tok] = 1\n",
    "\n",
    "sorted_freq_dist= sorted(freq_dis.items(), key=operator.itemgetter(1),\n",
    "reverse=True)\n",
    "\n",
    "\n",
    "\n",
    "doc7=pd.DataFrame(sorted_freq_dist)\n",
    "doc7.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc7</th>\n",
       "      <th>feq_doc7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc7  feq_doc7\n",
       "0  the       266"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc7.rename(columns={doc7.columns[0]: \"doc7\", doc7.columns[1]: \"feq_doc7\"}, inplace=True)\n",
    "\n",
    "doc7.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  the  504"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "filename = 'documents/document_8.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "#print (text)\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "\n",
    "q = list(filter(None,stripped))\n",
    "#print(w)\n",
    "\n",
    "import operator\n",
    "freq_dis={}\n",
    "for tok in q:\n",
    "    if tok in freq_dis:\n",
    "        freq_dis[tok] += 1\n",
    "    else:\n",
    "        freq_dis[tok] = 1\n",
    "\n",
    "sorted_freq_dist= sorted(freq_dis.items(), key=operator.itemgetter(1),\n",
    "reverse=True)\n",
    "\n",
    "\n",
    "\n",
    "doc8=pd.DataFrame(sorted_freq_dist)\n",
    "doc8.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc8</th>\n",
       "      <th>feq_doc8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc8  feq_doc8\n",
       "0  the       504"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc8.rename(columns={doc8.columns[0]: \"doc8\", doc8.columns[1]: \"feq_doc8\"}, inplace=True)\n",
    "\n",
    "doc8.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1\n",
       "0  the  23"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "filename = 'documents/document_9.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "#print (text)\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "\n",
    "r= list(filter(None,stripped))\n",
    "#print(w)\n",
    "\n",
    "import operator\n",
    "freq_dis={}\n",
    "for tok in r:\n",
    "    if tok in freq_dis:\n",
    "        freq_dis[tok] += 1\n",
    "    else:\n",
    "        freq_dis[tok] = 1\n",
    "\n",
    "sorted_freq_dist= sorted(freq_dis.items(), key=operator.itemgetter(1),\n",
    "reverse=True)\n",
    "\n",
    "\n",
    "\n",
    "doc9=pd.DataFrame(sorted_freq_dist)\n",
    "doc9.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc9</th>\n",
       "      <th>feq_doc9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc9  feq_doc9\n",
       "0  the        23"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc9.rename(columns={doc9.columns[0]: \"doc9\", doc9.columns[1]: \"feq_doc9\"}, inplace=True)\n",
    "\n",
    "doc9.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1\n",
       "0  the  26"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "filename = 'documents/document_10.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "#print (text)\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "\n",
    "s= list(filter(None,stripped))\n",
    "#print(w)\n",
    "\n",
    "import operator\n",
    "freq_dis={}\n",
    "for tok in s:\n",
    "    if tok in freq_dis:\n",
    "        freq_dis[tok] += 1\n",
    "    else:\n",
    "        freq_dis[tok] = 1\n",
    "\n",
    "sorted_freq_dist= sorted(freq_dis.items(), key=operator.itemgetter(1),\n",
    "reverse=True)\n",
    "\n",
    "\n",
    "\n",
    "doc10=pd.DataFrame(sorted_freq_dist)\n",
    "doc10.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc10</th>\n",
       "      <th>feq_doc10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc10  feq_doc10\n",
       "0   the         26"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc10.rename(columns={doc10.columns[0]: \"doc10\", doc10.columns[1]: \"feq_doc10\"}, inplace=True)\n",
    "\n",
    "doc10.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1\n",
       "0  1  148"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "filename = 'documents/document_11.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "#print (text)\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "\n",
    "t= list(filter(None,stripped))\n",
    "#print(w)\n",
    "\n",
    "import operator\n",
    "freq_dis={}\n",
    "for tok in t:\n",
    "    if tok in freq_dis:\n",
    "        freq_dis[tok] += 1\n",
    "    else:\n",
    "        freq_dis[tok] = 1\n",
    "\n",
    "sorted_freq_dist= sorted(freq_dis.items(), key=operator.itemgetter(1),\n",
    "reverse=True)\n",
    "\n",
    "\n",
    "\n",
    "doc11=pd.DataFrame(sorted_freq_dist)\n",
    "doc11.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc11</th>\n",
       "      <th>feq_doc11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc11  feq_doc11\n",
       "0     1        148"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc11.rename(columns={doc11.columns[0]: \"doc11\", doc11.columns[1]: \"feq_doc11\"}, inplace=True)\n",
    "\n",
    "doc11.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1\n",
       "0  the  62"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "filename = 'documents/document_12.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "#print (text)\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "\n",
    "u= list(filter(None,stripped))\n",
    "#print(w)\n",
    "\n",
    "import operator\n",
    "freq_dis={}\n",
    "for tok in u:\n",
    "    if tok in freq_dis:\n",
    "        freq_dis[tok] += 1\n",
    "    else:\n",
    "        freq_dis[tok] = 1\n",
    "\n",
    "sorted_freq_dist= sorted(freq_dis.items(), key=operator.itemgetter(1),\n",
    "reverse=True)\n",
    "\n",
    "\n",
    "\n",
    "doc12=pd.DataFrame(sorted_freq_dist)\n",
    "doc12.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc12</th>\n",
       "      <th>feq_doc12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc12  feq_doc12\n",
       "0   the         62"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc12.rename(columns={doc12.columns[0]: \"doc12\", doc12.columns[1]: \"feq_doc12\"}, inplace=True)\n",
    "\n",
    "doc12.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1\n",
       "0  the  30"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "filename = 'documents/document_13.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "#print (text)\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "\n",
    "v= list(filter(None,stripped))\n",
    "#print(w)\n",
    "\n",
    "import operator\n",
    "freq_dis={}\n",
    "for tok in v:\n",
    "    if tok in freq_dis:\n",
    "        freq_dis[tok] += 1\n",
    "    else:\n",
    "        freq_dis[tok] = 1\n",
    "\n",
    "sorted_freq_dist= sorted(freq_dis.items(), key=operator.itemgetter(1),\n",
    "reverse=True)\n",
    "\n",
    "\n",
    "\n",
    "doc13=pd.DataFrame(sorted_freq_dist)\n",
    "doc13.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc13</th>\n",
       "      <th>feq_doc13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc13  feq_doc13\n",
       "0   the         30"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc13.rename(columns={doc13.columns[0]: \"doc13\", doc13.columns[1]: \"feq_doc13\"}, inplace=True)\n",
    "\n",
    "doc13.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>report</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0   1\n",
       "0  report  98"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "filename = 'documents/document_14.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "#print (text)\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "\n",
    "x= list(filter(None,stripped))\n",
    "#print(w)\n",
    "\n",
    "import operator\n",
    "freq_dis={}\n",
    "for tok in x:\n",
    "    if tok in freq_dis:\n",
    "        freq_dis[tok] += 1\n",
    "    else:\n",
    "        freq_dis[tok] = 1\n",
    "\n",
    "sorted_freq_dist= sorted(freq_dis.items(), key=operator.itemgetter(1),\n",
    "reverse=True)\n",
    "\n",
    "\n",
    "\n",
    "doc14=pd.DataFrame(sorted_freq_dist)\n",
    "doc14.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc14</th>\n",
       "      <th>feq_doc14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>report</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    doc14  feq_doc14\n",
       "0  report         98"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc14.rename(columns={doc14.columns[0]: \"doc14\", doc14.columns[1]: \"feq_doc14\"}, inplace=True)\n",
    "\n",
    "doc14.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "################15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  the  261"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "filename = 'documents/document_15.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "#print (text)\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "\n",
    "y= list(filter(None,stripped))\n",
    "#print(w)\n",
    "\n",
    "import operator\n",
    "freq_dis={}\n",
    "for tok in y:\n",
    "    if tok in freq_dis:\n",
    "        freq_dis[tok] += 1\n",
    "    else:\n",
    "        freq_dis[tok] = 1\n",
    "\n",
    "sorted_freq_dist= sorted(freq_dis.items(), key=operator.itemgetter(1),\n",
    "reverse=True)\n",
    "\n",
    "\n",
    "\n",
    "doc15=pd.DataFrame(sorted_freq_dist)\n",
    "doc15.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc15</th>\n",
       "      <th>feq_doc15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc15  feq_doc15\n",
       "0   the        261"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc15.rename(columns={doc15.columns[0]: \"doc15\", doc15.columns[1]: \"feq_doc15\"}, inplace=True)\n",
    "\n",
    "doc15.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  the  106"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "filename = 'documents/document_16.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "#print (text)\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "\n",
    "r= list(filter(None,stripped))\n",
    "#print(w)\n",
    "\n",
    "import operator\n",
    "freq_dis={}\n",
    "for tok in r:\n",
    "    if tok in freq_dis:\n",
    "        freq_dis[tok] += 1\n",
    "    else:\n",
    "        freq_dis[tok] = 1\n",
    "\n",
    "sorted_freq_dist= sorted(freq_dis.items(), key=operator.itemgetter(1),\n",
    "reverse=True)\n",
    "\n",
    "\n",
    "\n",
    "doc16=pd.DataFrame(sorted_freq_dist)\n",
    "doc16.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc16</th>\n",
       "      <th>feq_doc16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc16  feq_doc16\n",
       "0   the        106"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc16.rename(columns={doc16.columns[0]: \"doc16\", doc16.columns[1]: \"feq_doc16\"}, inplace=True)\n",
    "\n",
    "doc16.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "################17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1\n",
       "0  the  80"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "filename = 'documents/document_17.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "#print (text)\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "\n",
    "rr= list(filter(None,stripped))\n",
    "#print(w)\n",
    "\n",
    "import operator\n",
    "freq_dis={}\n",
    "for tok in rr:\n",
    "    if tok in freq_dis:\n",
    "        freq_dis[tok] += 1\n",
    "    else:\n",
    "        freq_dis[tok] = 1\n",
    "\n",
    "sorted_freq_dist= sorted(freq_dis.items(), key=operator.itemgetter(1),\n",
    "reverse=True)\n",
    "\n",
    "\n",
    "\n",
    "doc17=pd.DataFrame(sorted_freq_dist)\n",
    "doc17.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc17</th>\n",
       "      <th>feq_doc17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc17  feq_doc17\n",
       "0   the         80"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc17.rename(columns={doc17.columns[0]: \"doc17\", doc17.columns[1]: \"feq_doc17\"}, inplace=True)\n",
    "\n",
    "doc17.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "################18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1\n",
       "0  the  18"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "filename = 'documents/document_18.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "#print (text)\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "\n",
    "aa= list(filter(None,stripped))\n",
    "#print(w)\n",
    "\n",
    "import operator\n",
    "freq_dis={}\n",
    "for tok in aa:\n",
    "    if tok in freq_dis:\n",
    "        freq_dis[tok] += 1\n",
    "    else:\n",
    "        freq_dis[tok] = 1\n",
    "\n",
    "sorted_freq_dist= sorted(freq_dis.items(), key=operator.itemgetter(1),\n",
    "reverse=True)\n",
    "\n",
    "\n",
    "\n",
    "doc18=pd.DataFrame(sorted_freq_dist)\n",
    "doc18.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc18</th>\n",
       "      <th>feq_doc18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc18  feq_doc18\n",
       "0   the         18"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc18.rename(columns={doc18.columns[0]: \"doc18\", doc18.columns[1]: \"feq_doc18\"}, inplace=True)\n",
    "\n",
    "doc18.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "################19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  the  894"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "filename = 'documents/document_19.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "#print (text)\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "\n",
    "aq= list(filter(None,stripped))\n",
    "#print(w)\n",
    "\n",
    "import operator\n",
    "freq_dis={}\n",
    "for tok in aq:\n",
    "    if tok in freq_dis:\n",
    "        freq_dis[tok] += 1\n",
    "    else:\n",
    "        freq_dis[tok] = 1\n",
    "\n",
    "sorted_freq_dist= sorted(freq_dis.items(), key=operator.itemgetter(1),\n",
    "reverse=True)\n",
    "\n",
    "\n",
    "\n",
    "doc19=pd.DataFrame(sorted_freq_dist)\n",
    "doc19.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc19</th>\n",
       "      <th>feq_doc19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc19  feq_doc19\n",
       "0   the        894"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc19.rename(columns={doc19.columns[0]: \"doc19\", doc19.columns[1]: \"feq_doc19\"}, inplace=True)\n",
    "\n",
    "doc19.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "################20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  the  963"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "filename = 'documents/document_20.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "#print (text)\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "\n",
    "ax= list(filter(None,stripped))\n",
    "#print(w)\n",
    "\n",
    "import operator\n",
    "freq_dis={}\n",
    "for tok in ax:\n",
    "    if tok in freq_dis:\n",
    "        freq_dis[tok] += 1\n",
    "    else:\n",
    "        freq_dis[tok] = 1\n",
    "\n",
    "sorted_freq_dist= sorted(freq_dis.items(), key=operator.itemgetter(1),\n",
    "reverse=True)\n",
    "\n",
    "\n",
    "\n",
    "doc20=pd.DataFrame(sorted_freq_dist)\n",
    "doc20.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc20</th>\n",
       "      <th>feq_doc20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc20  feq_doc20\n",
       "0   the        963"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc20.rename(columns={doc20.columns[0]: \"doc20\", doc20.columns[1]: \"feq_doc20\"}, inplace=True)\n",
    "\n",
    "doc20.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc1</th>\n",
       "      <th>feq_doc1</th>\n",
       "      <th>doc2</th>\n",
       "      <th>feq_doc2</th>\n",
       "      <th>doc3</th>\n",
       "      <th>feq_doc3</th>\n",
       "      <th>doc4</th>\n",
       "      <th>feq_doc4</th>\n",
       "      <th>doc5</th>\n",
       "      <th>feq_doc5</th>\n",
       "      <th>...</th>\n",
       "      <th>doc16</th>\n",
       "      <th>feq_doc16</th>\n",
       "      <th>doc17</th>\n",
       "      <th>feq_doc17</th>\n",
       "      <th>doc18</th>\n",
       "      <th>feq_doc18</th>\n",
       "      <th>doc19</th>\n",
       "      <th>feq_doc19</th>\n",
       "      <th>doc20</th>\n",
       "      <th>feq_doc20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>273.0</td>\n",
       "      <td>the</td>\n",
       "      <td>322.0</td>\n",
       "      <td>the</td>\n",
       "      <td>25.0</td>\n",
       "      <td>the</td>\n",
       "      <td>25.0</td>\n",
       "      <td>the</td>\n",
       "      <td>612.0</td>\n",
       "      <td>...</td>\n",
       "      <td>the</td>\n",
       "      <td>106.0</td>\n",
       "      <td>the</td>\n",
       "      <td>80.0</td>\n",
       "      <td>the</td>\n",
       "      <td>18.0</td>\n",
       "      <td>the</td>\n",
       "      <td>894</td>\n",
       "      <td>the</td>\n",
       "      <td>963.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc1  feq_doc1 doc2  feq_doc2 doc3  feq_doc3 doc4  feq_doc4 doc5  feq_doc5  \\\n",
       "0  the     273.0  the     322.0  the      25.0  the      25.0  the     612.0   \n",
       "\n",
       "   ... doc16  feq_doc16 doc17  feq_doc17 doc18  feq_doc18 doc19  feq_doc19  \\\n",
       "0  ...   the      106.0   the       80.0   the       18.0   the        894   \n",
       "\n",
       "  doc20  feq_doc20  \n",
       "0   the      963.0  \n",
       "\n",
       "[1 rows x 42 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc=pd.concat([doc1,doc2,doc3,doc4,doc5,doc6,doc7,doc8,doc9,doc10\n",
    "              ,doc11,doc12,doc12,doc13,doc14,doc15,doc16,doc17,doc18\n",
    "              ,doc19,doc20], axis=1, sort=False)\n",
    "doc.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc1</th>\n",
       "      <th>feq_doc1</th>\n",
       "      <th>doc2</th>\n",
       "      <th>feq_doc2</th>\n",
       "      <th>doc3</th>\n",
       "      <th>feq_doc3</th>\n",
       "      <th>doc4</th>\n",
       "      <th>feq_doc4</th>\n",
       "      <th>doc5</th>\n",
       "      <th>feq_doc5</th>\n",
       "      <th>...</th>\n",
       "      <th>doc16</th>\n",
       "      <th>feq_doc16</th>\n",
       "      <th>doc17</th>\n",
       "      <th>feq_doc17</th>\n",
       "      <th>doc18</th>\n",
       "      <th>feq_doc18</th>\n",
       "      <th>doc19</th>\n",
       "      <th>feq_doc19</th>\n",
       "      <th>doc20</th>\n",
       "      <th>feq_doc20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>273</td>\n",
       "      <td>the</td>\n",
       "      <td>322</td>\n",
       "      <td>the</td>\n",
       "      <td>25</td>\n",
       "      <td>the</td>\n",
       "      <td>25</td>\n",
       "      <td>the</td>\n",
       "      <td>612</td>\n",
       "      <td>...</td>\n",
       "      <td>the</td>\n",
       "      <td>106</td>\n",
       "      <td>the</td>\n",
       "      <td>80</td>\n",
       "      <td>the</td>\n",
       "      <td>18</td>\n",
       "      <td>the</td>\n",
       "      <td>894</td>\n",
       "      <td>the</td>\n",
       "      <td>963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>138</td>\n",
       "      <td>of</td>\n",
       "      <td>111</td>\n",
       "      <td>wanzer</td>\n",
       "      <td>15</td>\n",
       "      <td>wanzer</td>\n",
       "      <td>15</td>\n",
       "      <td>of</td>\n",
       "      <td>191</td>\n",
       "      <td>...</td>\n",
       "      <td>and</td>\n",
       "      <td>56</td>\n",
       "      <td>in</td>\n",
       "      <td>57</td>\n",
       "      <td>and</td>\n",
       "      <td>16</td>\n",
       "      <td>of</td>\n",
       "      <td>600</td>\n",
       "      <td>of</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "      <td>123</td>\n",
       "      <td>and</td>\n",
       "      <td>91</td>\n",
       "      <td>a</td>\n",
       "      <td>9</td>\n",
       "      <td>a</td>\n",
       "      <td>9</td>\n",
       "      <td>in</td>\n",
       "      <td>189</td>\n",
       "      <td>...</td>\n",
       "      <td>in</td>\n",
       "      <td>55</td>\n",
       "      <td>she</td>\n",
       "      <td>35</td>\n",
       "      <td>of</td>\n",
       "      <td>15</td>\n",
       "      <td>in</td>\n",
       "      <td>486</td>\n",
       "      <td>king</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>84</td>\n",
       "      <td>a</td>\n",
       "      <td>57</td>\n",
       "      <td>in</td>\n",
       "      <td>9</td>\n",
       "      <td>in</td>\n",
       "      <td>9</td>\n",
       "      <td>and</td>\n",
       "      <td>173</td>\n",
       "      <td>...</td>\n",
       "      <td>of</td>\n",
       "      <td>50</td>\n",
       "      <td>and</td>\n",
       "      <td>30</td>\n",
       "      <td>a</td>\n",
       "      <td>14</td>\n",
       "      <td>and</td>\n",
       "      <td>429</td>\n",
       "      <td>and</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>81</td>\n",
       "      <td>in</td>\n",
       "      <td>56</td>\n",
       "      <td>was</td>\n",
       "      <td>8</td>\n",
       "      <td>was</td>\n",
       "      <td>8</td>\n",
       "      <td>to</td>\n",
       "      <td>136</td>\n",
       "      <td>...</td>\n",
       "      <td>menage</td>\n",
       "      <td>49</td>\n",
       "      <td>of</td>\n",
       "      <td>22</td>\n",
       "      <td>in</td>\n",
       "      <td>11</td>\n",
       "      <td>franklin</td>\n",
       "      <td>402</td>\n",
       "      <td>in</td>\n",
       "      <td>387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>is</td>\n",
       "      <td>62</td>\n",
       "      <td>cell</td>\n",
       "      <td>54</td>\n",
       "      <td>and</td>\n",
       "      <td>8</td>\n",
       "      <td>and</td>\n",
       "      <td>8</td>\n",
       "      <td>a</td>\n",
       "      <td>121</td>\n",
       "      <td>...</td>\n",
       "      <td>a</td>\n",
       "      <td>41</td>\n",
       "      <td>team</td>\n",
       "      <td>20</td>\n",
       "      <td>haston</td>\n",
       "      <td>7</td>\n",
       "      <td>a</td>\n",
       "      <td>364</td>\n",
       "      <td>to</td>\n",
       "      <td>387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>as</td>\n",
       "      <td>59</td>\n",
       "      <td>is</td>\n",
       "      <td>53</td>\n",
       "      <td>royals</td>\n",
       "      <td>7</td>\n",
       "      <td>royals</td>\n",
       "      <td>7</td>\n",
       "      <td>oktoberfest</td>\n",
       "      <td>105</td>\n",
       "      <td>...</td>\n",
       "      <td>to</td>\n",
       "      <td>39</td>\n",
       "      <td>ohea</td>\n",
       "      <td>16</td>\n",
       "      <td>book</td>\n",
       "      <td>5</td>\n",
       "      <td>to</td>\n",
       "      <td>345</td>\n",
       "      <td>a</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>in</td>\n",
       "      <td>54</td>\n",
       "      <td>as</td>\n",
       "      <td>42</td>\n",
       "      <td>he</td>\n",
       "      <td>6</td>\n",
       "      <td>he</td>\n",
       "      <td>6</td>\n",
       "      <td>is</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>26</td>\n",
       "      <td>for</td>\n",
       "      <td>16</td>\n",
       "      <td>is</td>\n",
       "      <td>4</td>\n",
       "      <td>his</td>\n",
       "      <td>231</td>\n",
       "      <td>that</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>that</td>\n",
       "      <td>41</td>\n",
       "      <td>air</td>\n",
       "      <td>41</td>\n",
       "      <td>hall</td>\n",
       "      <td>5</td>\n",
       "      <td>hall</td>\n",
       "      <td>5</td>\n",
       "      <td>was</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>was</td>\n",
       "      <td>24</td>\n",
       "      <td>was</td>\n",
       "      <td>16</td>\n",
       "      <td>rising</td>\n",
       "      <td>4</td>\n",
       "      <td>he</td>\n",
       "      <td>217</td>\n",
       "      <td>was</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>with</td>\n",
       "      <td>38</td>\n",
       "      <td>to</td>\n",
       "      <td>37</td>\n",
       "      <td>to</td>\n",
       "      <td>5</td>\n",
       "      <td>to</td>\n",
       "      <td>5</td>\n",
       "      <td>for</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>he</td>\n",
       "      <td>24</td>\n",
       "      <td>at</td>\n",
       "      <td>15</td>\n",
       "      <td>dead</td>\n",
       "      <td>4</td>\n",
       "      <td>was</td>\n",
       "      <td>210</td>\n",
       "      <td>s</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>or</td>\n",
       "      <td>32</td>\n",
       "      <td>at</td>\n",
       "      <td>34</td>\n",
       "      <td>season</td>\n",
       "      <td>5</td>\n",
       "      <td>season</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>his</td>\n",
       "      <td>17</td>\n",
       "      <td>a</td>\n",
       "      <td>15</td>\n",
       "      <td>moon</td>\n",
       "      <td>4</td>\n",
       "      <td>that</td>\n",
       "      <td>142</td>\n",
       "      <td>his</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>are</td>\n",
       "      <td>31</td>\n",
       "      <td>it</td>\n",
       "      <td>33</td>\n",
       "      <td>as</td>\n",
       "      <td>4</td>\n",
       "      <td>as</td>\n",
       "      <td>4</td>\n",
       "      <td>with</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>minneapolis</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>echo</td>\n",
       "      <td>4</td>\n",
       "      <td>as</td>\n",
       "      <td>136</td>\n",
       "      <td>he</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>santera</td>\n",
       "      <td>28</td>\n",
       "      <td>circulation</td>\n",
       "      <td>32</td>\n",
       "      <td>basketball</td>\n",
       "      <td>4</td>\n",
       "      <td>basketball</td>\n",
       "      <td>4</td>\n",
       "      <td>beer</td>\n",
       "      <td>47</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>with</td>\n",
       "      <td>13</td>\n",
       "      <td>magical</td>\n",
       "      <td>4</td>\n",
       "      <td>s</td>\n",
       "      <td>133</td>\n",
       "      <td>for</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>be</td>\n",
       "      <td>24</td>\n",
       "      <td>are</td>\n",
       "      <td>32</td>\n",
       "      <td>coach</td>\n",
       "      <td>4</td>\n",
       "      <td>coach</td>\n",
       "      <td>4</td>\n",
       "      <td>festival</td>\n",
       "      <td>47</td>\n",
       "      <td>...</td>\n",
       "      <td>for</td>\n",
       "      <td>15</td>\n",
       "      <td>to</td>\n",
       "      <td>13</td>\n",
       "      <td>whispers</td>\n",
       "      <td>4</td>\n",
       "      <td>on</td>\n",
       "      <td>133</td>\n",
       "      <td>on</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>for</td>\n",
       "      <td>23</td>\n",
       "      <td>hadley</td>\n",
       "      <td>31</td>\n",
       "      <td>of</td>\n",
       "      <td>4</td>\n",
       "      <td>of</td>\n",
       "      <td>4</td>\n",
       "      <td>at</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>with</td>\n",
       "      <td>14</td>\n",
       "      <td>season</td>\n",
       "      <td>13</td>\n",
       "      <td>published</td>\n",
       "      <td>4</td>\n",
       "      <td>for</td>\n",
       "      <td>130</td>\n",
       "      <td>with</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>their</td>\n",
       "      <td>23</td>\n",
       "      <td>polar</td>\n",
       "      <td>29</td>\n",
       "      <td>with</td>\n",
       "      <td>4</td>\n",
       "      <td>with</td>\n",
       "      <td>4</td>\n",
       "      <td>on</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>king</td>\n",
       "      <td>13</td>\n",
       "      <td>australian</td>\n",
       "      <td>12</td>\n",
       "      <td>for</td>\n",
       "      <td>4</td>\n",
       "      <td>by</td>\n",
       "      <td>114</td>\n",
       "      <td>by</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>by</td>\n",
       "      <td>21</td>\n",
       "      <td>by</td>\n",
       "      <td>27</td>\n",
       "      <td>for</td>\n",
       "      <td>4</td>\n",
       "      <td>for</td>\n",
       "      <td>4</td>\n",
       "      <td>by</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>by</td>\n",
       "      <td>13</td>\n",
       "      <td>2012</td>\n",
       "      <td>11</td>\n",
       "      <td>elephants</td>\n",
       "      <td>4</td>\n",
       "      <td>with</td>\n",
       "      <td>96</td>\n",
       "      <td>i</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>orichs</td>\n",
       "      <td>21</td>\n",
       "      <td>ferrel</td>\n",
       "      <td>27</td>\n",
       "      <td>also</td>\n",
       "      <td>3</td>\n",
       "      <td>also</td>\n",
       "      <td>3</td>\n",
       "      <td>s</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>land</td>\n",
       "      <td>12</td>\n",
       "      <td>basketball</td>\n",
       "      <td>11</td>\n",
       "      <td>s</td>\n",
       "      <td>4</td>\n",
       "      <td>from</td>\n",
       "      <td>80</td>\n",
       "      <td>rights</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>known</td>\n",
       "      <td>19</td>\n",
       "      <td>that</td>\n",
       "      <td>25</td>\n",
       "      <td>at</td>\n",
       "      <td>3</td>\n",
       "      <td>at</td>\n",
       "      <td>3</td>\n",
       "      <td>tents</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>were</td>\n",
       "      <td>11</td>\n",
       "      <td>national</td>\n",
       "      <td>11</td>\n",
       "      <td>was</td>\n",
       "      <td>4</td>\n",
       "      <td>it</td>\n",
       "      <td>64</td>\n",
       "      <td>as</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>traditional</td>\n",
       "      <td>19</td>\n",
       "      <td>surface</td>\n",
       "      <td>22</td>\n",
       "      <td>seton</td>\n",
       "      <td>3</td>\n",
       "      <td>seton</td>\n",
       "      <td>3</td>\n",
       "      <td>tent</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>real</td>\n",
       "      <td>10</td>\n",
       "      <td>her</td>\n",
       "      <td>11</td>\n",
       "      <td>to</td>\n",
       "      <td>4</td>\n",
       "      <td>philadelphia</td>\n",
       "      <td>59</td>\n",
       "      <td>civil</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>from</td>\n",
       "      <td>19</td>\n",
       "      <td>cells</td>\n",
       "      <td>18</td>\n",
       "      <td>after</td>\n",
       "      <td>3</td>\n",
       "      <td>after</td>\n",
       "      <td>3</td>\n",
       "      <td>munich</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>estate</td>\n",
       "      <td>10</td>\n",
       "      <td>game</td>\n",
       "      <td>10</td>\n",
       "      <td>from</td>\n",
       "      <td>3</td>\n",
       "      <td>benjamin</td>\n",
       "      <td>58</td>\n",
       "      <td>at</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>healing</td>\n",
       "      <td>17</td>\n",
       "      <td>this</td>\n",
       "      <td>17</td>\n",
       "      <td>team</td>\n",
       "      <td>3</td>\n",
       "      <td>team</td>\n",
       "      <td>3</td>\n",
       "      <td>as</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>city</td>\n",
       "      <td>10</td>\n",
       "      <td>wnbl</td>\n",
       "      <td>9</td>\n",
       "      <td>fiction</td>\n",
       "      <td>3</td>\n",
       "      <td>an</td>\n",
       "      <td>58</td>\n",
       "      <td>from</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>pacific</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>from</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>minnesota</td>\n",
       "      <td>9</td>\n",
       "      <td>played</td>\n",
       "      <td>9</td>\n",
       "      <td>historical</td>\n",
       "      <td>3</td>\n",
       "      <td>which</td>\n",
       "      <td>58</td>\n",
       "      <td>an</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>an</td>\n",
       "      <td>16</td>\n",
       "      <td>from</td>\n",
       "      <td>16</td>\n",
       "      <td>star</td>\n",
       "      <td>3</td>\n",
       "      <td>star</td>\n",
       "      <td>3</td>\n",
       "      <td>are</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>as</td>\n",
       "      <td>8</td>\n",
       "      <td>s</td>\n",
       "      <td>7</td>\n",
       "      <td>blood</td>\n",
       "      <td>3</td>\n",
       "      <td>had</td>\n",
       "      <td>55</td>\n",
       "      <td>it</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>also</td>\n",
       "      <td>15</td>\n",
       "      <td>on</td>\n",
       "      <td>16</td>\n",
       "      <td>were</td>\n",
       "      <td>3</td>\n",
       "      <td>were</td>\n",
       "      <td>3</td>\n",
       "      <td>this</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>at</td>\n",
       "      <td>8</td>\n",
       "      <td>points</td>\n",
       "      <td>7</td>\n",
       "      <td>doves</td>\n",
       "      <td>3</td>\n",
       "      <td>pennsylvania</td>\n",
       "      <td>54</td>\n",
       "      <td>had</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>they</td>\n",
       "      <td>15</td>\n",
       "      <td>s</td>\n",
       "      <td>16</td>\n",
       "      <td>nba</td>\n",
       "      <td>3</td>\n",
       "      <td>nba</td>\n",
       "      <td>3</td>\n",
       "      <td>first</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>had</td>\n",
       "      <td>8</td>\n",
       "      <td>per</td>\n",
       "      <td>7</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>is</td>\n",
       "      <td>52</td>\n",
       "      <td>have</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>on</td>\n",
       "      <td>14</td>\n",
       "      <td>which</td>\n",
       "      <td>16</td>\n",
       "      <td>his</td>\n",
       "      <td>3</td>\n",
       "      <td>his</td>\n",
       "      <td>3</td>\n",
       "      <td>were</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>new</td>\n",
       "      <td>8</td>\n",
       "      <td>jenna</td>\n",
       "      <td>6</td>\n",
       "      <td>an</td>\n",
       "      <td>3</td>\n",
       "      <td>at</td>\n",
       "      <td>52</td>\n",
       "      <td>is</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>orich</td>\n",
       "      <td>14</td>\n",
       "      <td>equator</td>\n",
       "      <td>14</td>\n",
       "      <td>on</td>\n",
       "      <td>3</td>\n",
       "      <td>on</td>\n",
       "      <td>3</td>\n",
       "      <td>it</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>business</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>career</td>\n",
       "      <td>3</td>\n",
       "      <td>first</td>\n",
       "      <td>51</td>\n",
       "      <td>march</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>which</td>\n",
       "      <td>14</td>\n",
       "      <td>winds</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>which</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>from</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>october</td>\n",
       "      <td>3</td>\n",
       "      <td>american</td>\n",
       "      <td>49</td>\n",
       "      <td>luther</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>religion</td>\n",
       "      <td>12</td>\n",
       "      <td>toward</td>\n",
       "      <td>14</td>\n",
       "      <td>january</td>\n",
       "      <td>2</td>\n",
       "      <td>january</td>\n",
       "      <td>2</td>\n",
       "      <td>an</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>on</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>class</td>\n",
       "      <td>3</td>\n",
       "      <td>be</td>\n",
       "      <td>47</td>\n",
       "      <td>movement</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>du</td>\n",
       "      <td>5</td>\n",
       "      <td>its</td>\n",
       "      <td>4</td>\n",
       "      <td>195051</td>\n",
       "      <td>1</td>\n",
       "      <td>195051</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>much</td>\n",
       "      <td>2</td>\n",
       "      <td>information</td>\n",
       "      <td>2</td>\n",
       "      <td>been</td>\n",
       "      <td>1</td>\n",
       "      <td>born</td>\n",
       "      <td>14</td>\n",
       "      <td>years</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>health</td>\n",
       "      <td>5</td>\n",
       "      <td>convective</td>\n",
       "      <td>4</td>\n",
       "      <td>national</td>\n",
       "      <td>1</td>\n",
       "      <td>national</td>\n",
       "      <td>1</td>\n",
       "      <td>today</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>harriet</td>\n",
       "      <td>2</td>\n",
       "      <td>traralgon</td>\n",
       "      <td>2</td>\n",
       "      <td>augmented</td>\n",
       "      <td>1</td>\n",
       "      <td>read</td>\n",
       "      <td>14</td>\n",
       "      <td>many</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>regla</td>\n",
       "      <td>4</td>\n",
       "      <td>time</td>\n",
       "      <td>4</td>\n",
       "      <td>association</td>\n",
       "      <td>1</td>\n",
       "      <td>association</td>\n",
       "      <td>1</td>\n",
       "      <td>outside</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>luxury</td>\n",
       "      <td>2</td>\n",
       "      <td>listed</td>\n",
       "      <td>2</td>\n",
       "      <td>recent</td>\n",
       "      <td>1</td>\n",
       "      <td>university</td>\n",
       "      <td>14</td>\n",
       "      <td>when</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>och</td>\n",
       "      <td>4</td>\n",
       "      <td>driven</td>\n",
       "      <td>4</td>\n",
       "      <td>title</td>\n",
       "      <td>1</td>\n",
       "      <td>title</td>\n",
       "      <td>1</td>\n",
       "      <td>years</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>tallest</td>\n",
       "      <td>2</td>\n",
       "      <td>lb</td>\n",
       "      <td>2</td>\n",
       "      <td>years</td>\n",
       "      <td>1</td>\n",
       "      <td>religious</td>\n",
       "      <td>14</td>\n",
       "      <td>school</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>la</td>\n",
       "      <td>4</td>\n",
       "      <td>whose</td>\n",
       "      <td>4</td>\n",
       "      <td>entire</td>\n",
       "      <td>1</td>\n",
       "      <td>entire</td>\n",
       "      <td>1</td>\n",
       "      <td>time</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>skyscraper</td>\n",
       "      <td>2</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "      <td>his</td>\n",
       "      <td>1</td>\n",
       "      <td>college</td>\n",
       "      <td>14</td>\n",
       "      <td>however</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>sink</td>\n",
       "      <td>4</td>\n",
       "      <td>career</td>\n",
       "      <td>1</td>\n",
       "      <td>career</td>\n",
       "      <td>1</td>\n",
       "      <td>citation</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>battle</td>\n",
       "      <td>2</td>\n",
       "      <td>school</td>\n",
       "      <td>2</td>\n",
       "      <td>debut</td>\n",
       "      <td>1</td>\n",
       "      <td>electrical</td>\n",
       "      <td>14</td>\n",
       "      <td>my</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>spanish</td>\n",
       "      <td>4</td>\n",
       "      <td>process</td>\n",
       "      <td>4</td>\n",
       "      <td>retiring</td>\n",
       "      <td>1</td>\n",
       "      <td>retiring</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>over</td>\n",
       "      <td>2</td>\n",
       "      <td>caulfield</td>\n",
       "      <td>2</td>\n",
       "      <td>novel</td>\n",
       "      <td>1</td>\n",
       "      <td>named</td>\n",
       "      <td>14</td>\n",
       "      <td>both</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>means</td>\n",
       "      <td>4</td>\n",
       "      <td>near</td>\n",
       "      <td>4</td>\n",
       "      <td>play</td>\n",
       "      <td>1</td>\n",
       "      <td>play</td>\n",
       "      <td>1</td>\n",
       "      <td>police</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>deal</td>\n",
       "      <td>2</td>\n",
       "      <td>grammar</td>\n",
       "      <td>2</td>\n",
       "      <td>followed</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>social</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>syncretized</td>\n",
       "      <td>4</td>\n",
       "      <td>poles</td>\n",
       "      <td>4</td>\n",
       "      <td>end</td>\n",
       "      <td>1</td>\n",
       "      <td>end</td>\n",
       "      <td>1</td>\n",
       "      <td>2005</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>panic</td>\n",
       "      <td>2</td>\n",
       "      <td>bendigo</td>\n",
       "      <td>2</td>\n",
       "      <td>almost</td>\n",
       "      <td>1</td>\n",
       "      <td>father</td>\n",
       "      <td>14</td>\n",
       "      <td>party</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>their</td>\n",
       "      <td>4</td>\n",
       "      <td>1957</td>\n",
       "      <td>1</td>\n",
       "      <td>1957</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1893</td>\n",
       "      <td>2</td>\n",
       "      <td>spirit</td>\n",
       "      <td>2</td>\n",
       "      <td>contemporaneously</td>\n",
       "      <td>1</td>\n",
       "      <td>three</td>\n",
       "      <td>14</td>\n",
       "      <td>southern</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>such</td>\n",
       "      <td>4</td>\n",
       "      <td>fivetime</td>\n",
       "      <td>1</td>\n",
       "      <td>fivetime</td>\n",
       "      <td>1</td>\n",
       "      <td>smoking</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>fled</td>\n",
       "      <td>2</td>\n",
       "      <td>arras</td>\n",
       "      <td>2</td>\n",
       "      <td>first</td>\n",
       "      <td>1</td>\n",
       "      <td>can</td>\n",
       "      <td>14</td>\n",
       "      <td>christian</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>american</td>\n",
       "      <td>4</td>\n",
       "      <td>latitudinal</td>\n",
       "      <td>4</td>\n",
       "      <td>allnba</td>\n",
       "      <td>1</td>\n",
       "      <td>allnba</td>\n",
       "      <td>1</td>\n",
       "      <td>small</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>avoid</td>\n",
       "      <td>2</td>\n",
       "      <td>los</td>\n",
       "      <td>2</td>\n",
       "      <td>rewritten</td>\n",
       "      <td>1</td>\n",
       "      <td>these</td>\n",
       "      <td>14</td>\n",
       "      <td>april</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>sacrifice</td>\n",
       "      <td>4</td>\n",
       "      <td>pattern</td>\n",
       "      <td>4</td>\n",
       "      <td>second</td>\n",
       "      <td>1</td>\n",
       "      <td>second</td>\n",
       "      <td>1</td>\n",
       "      <td>but</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>embezzlement</td>\n",
       "      <td>2</td>\n",
       "      <td>angeles</td>\n",
       "      <td>2</td>\n",
       "      <td>final</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>became</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>into</td>\n",
       "      <td>4</td>\n",
       "      <td>solar</td>\n",
       "      <td>4</td>\n",
       "      <td>three</td>\n",
       "      <td>1</td>\n",
       "      <td>three</td>\n",
       "      <td>1</td>\n",
       "      <td>historical</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>dropped</td>\n",
       "      <td>2</td>\n",
       "      <td>sparks</td>\n",
       "      <td>2</td>\n",
       "      <td>form</td>\n",
       "      <td>1</td>\n",
       "      <td>postmaster</td>\n",
       "      <td>13</td>\n",
       "      <td>called</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>what</td>\n",
       "      <td>4</td>\n",
       "      <td>low</td>\n",
       "      <td>4</td>\n",
       "      <td>consecutive</td>\n",
       "      <td>1</td>\n",
       "      <td>consecutive</td>\n",
       "      <td>1</td>\n",
       "      <td>augustiner</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>key</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>september</td>\n",
       "      <td>1</td>\n",
       "      <td>general</td>\n",
       "      <td>13</td>\n",
       "      <td>new</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>period</td>\n",
       "      <td>4</td>\n",
       "      <td>main</td>\n",
       "      <td>4</td>\n",
       "      <td>times</td>\n",
       "      <td>1</td>\n",
       "      <td>times</td>\n",
       "      <td>1</td>\n",
       "      <td>closed</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>witnesses</td>\n",
       "      <td>2</td>\n",
       "      <td>allstar</td>\n",
       "      <td>2</td>\n",
       "      <td>spartan</td>\n",
       "      <td>1</td>\n",
       "      <td>early</td>\n",
       "      <td>13</td>\n",
       "      <td>police</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>all</td>\n",
       "      <td>4</td>\n",
       "      <td>trade</td>\n",
       "      <td>4</td>\n",
       "      <td>195152</td>\n",
       "      <td>1</td>\n",
       "      <td>195152</td>\n",
       "      <td>1</td>\n",
       "      <td>well</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>testify</td>\n",
       "      <td>2</td>\n",
       "      <td>hide</td>\n",
       "      <td>2</td>\n",
       "      <td>style</td>\n",
       "      <td>1</td>\n",
       "      <td>work</td>\n",
       "      <td>13</td>\n",
       "      <td>americans</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>term</td>\n",
       "      <td>4</td>\n",
       "      <td>side</td>\n",
       "      <td>4</td>\n",
       "      <td>ever</td>\n",
       "      <td>1</td>\n",
       "      <td>ever</td>\n",
       "      <td>1</td>\n",
       "      <td>germany</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>him</td>\n",
       "      <td>2</td>\n",
       "      <td>association</td>\n",
       "      <td>2</td>\n",
       "      <td>that</td>\n",
       "      <td>1</td>\n",
       "      <td>folger</td>\n",
       "      <td>13</td>\n",
       "      <td>because</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>priest</td>\n",
       "      <td>4</td>\n",
       "      <td>creates</td>\n",
       "      <td>4</td>\n",
       "      <td>shoot</td>\n",
       "      <td>1</td>\n",
       "      <td>shoot</td>\n",
       "      <td>1</td>\n",
       "      <td>name</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>spent</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>often</td>\n",
       "      <td>1</td>\n",
       "      <td>published</td>\n",
       "      <td>13</td>\n",
       "      <td>up</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>first</td>\n",
       "      <td>4</td>\n",
       "      <td>parallel</td>\n",
       "      <td>4</td>\n",
       "      <td>over</td>\n",
       "      <td>1</td>\n",
       "      <td>over</td>\n",
       "      <td>1</td>\n",
       "      <td>example</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>working</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>requires</td>\n",
       "      <td>1</td>\n",
       "      <td>over</td>\n",
       "      <td>13</td>\n",
       "      <td>main</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>represent</td>\n",
       "      <td>4</td>\n",
       "      <td>equatorial</td>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>chicken</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>never</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>reader</td>\n",
       "      <td>1</td>\n",
       "      <td>see</td>\n",
       "      <td>12</td>\n",
       "      <td>say</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>warriors</td>\n",
       "      <td>4</td>\n",
       "      <td>due</td>\n",
       "      <td>4</td>\n",
       "      <td>free</td>\n",
       "      <td>1</td>\n",
       "      <td>free</td>\n",
       "      <td>1</td>\n",
       "      <td>now</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>worked</td>\n",
       "      <td>2</td>\n",
       "      <td>overseas</td>\n",
       "      <td>2</td>\n",
       "      <td>provide</td>\n",
       "      <td>1</td>\n",
       "      <td>john</td>\n",
       "      <td>12</td>\n",
       "      <td>are</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>initiation</td>\n",
       "      <td>4</td>\n",
       "      <td>conservation</td>\n",
       "      <td>4</td>\n",
       "      <td>throw</td>\n",
       "      <td>1</td>\n",
       "      <td>throw</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>on</td>\n",
       "      <td>2</td>\n",
       "      <td>linkages</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>birmingham</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>water</td>\n",
       "      <td>4</td>\n",
       "      <td>flow</td>\n",
       "      <td>4</td>\n",
       "      <td>line</td>\n",
       "      <td>1</td>\n",
       "      <td>line</td>\n",
       "      <td>1</td>\n",
       "      <td>restaurateurs</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>philanthropy</td>\n",
       "      <td>2</td>\n",
       "      <td>luke</td>\n",
       "      <td>2</td>\n",
       "      <td>within</td>\n",
       "      <td>1</td>\n",
       "      <td>death</td>\n",
       "      <td>12</td>\n",
       "      <td>selma</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>specific</td>\n",
       "      <td>4</td>\n",
       "      <td>though</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>costume</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>best</td>\n",
       "      <td>2</td>\n",
       "      <td>story</td>\n",
       "      <td>1</td>\n",
       "      <td>deborah</td>\n",
       "      <td>12</td>\n",
       "      <td>nonviolence</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>however</td>\n",
       "      <td>4</td>\n",
       "      <td>easterlies</td>\n",
       "      <td>4</td>\n",
       "      <td>naismith</td>\n",
       "      <td>1</td>\n",
       "      <td>naismith</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>collapse</td>\n",
       "      <td>2</td>\n",
       "      <td>teammate</td>\n",
       "      <td>2</td>\n",
       "      <td>line</td>\n",
       "      <td>1</td>\n",
       "      <td>electricity</td>\n",
       "      <td>12</td>\n",
       "      <td>has</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>once</td>\n",
       "      <td>4</td>\n",
       "      <td>tropopause</td>\n",
       "      <td>4</td>\n",
       "      <td>memorial</td>\n",
       "      <td>1</td>\n",
       "      <td>memorial</td>\n",
       "      <td>1</td>\n",
       "      <td>ludwig</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>represented</td>\n",
       "      <td>2</td>\n",
       "      <td>characterisation</td>\n",
       "      <td>1</td>\n",
       "      <td>several</td>\n",
       "      <td>12</td>\n",
       "      <td>could</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>necklace</td>\n",
       "      <td>4</td>\n",
       "      <td>temperatures</td>\n",
       "      <td>4</td>\n",
       "      <td>1987</td>\n",
       "      <td>1</td>\n",
       "      <td>1987</td>\n",
       "      <td>1</td>\n",
       "      <td>races</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>notes</td>\n",
       "      <td>2</td>\n",
       "      <td>u16</td>\n",
       "      <td>2</td>\n",
       "      <td>themes</td>\n",
       "      <td>1</td>\n",
       "      <td>scientific</td>\n",
       "      <td>12</td>\n",
       "      <td>any</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>blood</td>\n",
       "      <td>4</td>\n",
       "      <td>north</td>\n",
       "      <td>4</td>\n",
       "      <td>would</td>\n",
       "      <td>1</td>\n",
       "      <td>would</td>\n",
       "      <td>1</td>\n",
       "      <td>tradition</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>ais</td>\n",
       "      <td>2</td>\n",
       "      <td>suffering</td>\n",
       "      <td>1</td>\n",
       "      <td>national</td>\n",
       "      <td>12</td>\n",
       "      <td>before</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>elegu</td>\n",
       "      <td>4</td>\n",
       "      <td>even</td>\n",
       "      <td>4</td>\n",
       "      <td>well</td>\n",
       "      <td>1</td>\n",
       "      <td>well</td>\n",
       "      <td>1</td>\n",
       "      <td>however</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>father</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>underprivileged</td>\n",
       "      <td>1</td>\n",
       "      <td>britain</td>\n",
       "      <td>12</td>\n",
       "      <td>their</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows  42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            doc1  feq_doc1          doc2  feq_doc2         doc3  feq_doc3  \\\n",
       "0            the       273           the       322          the        25   \n",
       "1             of       138            of       111       wanzer        15   \n",
       "2            and       123           and        91            a         9   \n",
       "3              a        84             a        57           in         9   \n",
       "4             to        81            in        56          was         8   \n",
       "5             is        62          cell        54          and         8   \n",
       "6             as        59            is        53       royals         7   \n",
       "7             in        54            as        42           he         6   \n",
       "8           that        41           air        41         hall         5   \n",
       "9           with        38            to        37           to         5   \n",
       "10            or        32            at        34       season         5   \n",
       "11           are        31            it        33           as         4   \n",
       "12      santera        28   circulation        32   basketball         4   \n",
       "13            be        24           are        32        coach         4   \n",
       "14           for        23        hadley        31           of         4   \n",
       "15         their        23         polar        29         with         4   \n",
       "16            by        21            by        27          for         4   \n",
       "17       orichs        21        ferrel        27         also         3   \n",
       "18         known        19          that        25           at         3   \n",
       "19   traditional        19       surface        22        seton         3   \n",
       "20          from        19         cells        18        after         3   \n",
       "21       healing        17          this        17         team         3   \n",
       "22             6        17       pacific        17            1         3   \n",
       "23            an        16          from        16         star         3   \n",
       "24          also        15            on        16         were         3   \n",
       "25          they        15             s        16          nba         3   \n",
       "26            on        14         which        16          his         3   \n",
       "27        orich        14       equator        14           on         3   \n",
       "28         which        14         winds        14            4         2   \n",
       "29      religion        12        toward        14      january         2   \n",
       "..           ...       ...           ...       ...          ...       ...   \n",
       "110           du         5           its         4      195051         1   \n",
       "111       health         5    convective         4     national         1   \n",
       "112        regla         4          time         4  association         1   \n",
       "113         och         4        driven         4        title         1   \n",
       "114           la         4         whose         4       entire         1   \n",
       "115            2         4          sink         4       career         1   \n",
       "116      spanish         4       process         4     retiring         1   \n",
       "117        means         4          near         4         play         1   \n",
       "118  syncretized         4         poles         4          end         1   \n",
       "119           21         4         their         4         1957         1   \n",
       "120           25         4          such         4     fivetime         1   \n",
       "121     american         4   latitudinal         4       allnba         1   \n",
       "122    sacrifice         4       pattern         4       second         1   \n",
       "123         into         4         solar         4        three         1   \n",
       "124         what         4           low         4  consecutive         1   \n",
       "125       period         4          main         4        times         1   \n",
       "126          all         4         trade         4      195152         1   \n",
       "127         term         4          side         4         ever         1   \n",
       "128       priest         4       creates         4        shoot         1   \n",
       "129        first         4      parallel         4         over         1   \n",
       "130    represent         4    equatorial         4           90         1   \n",
       "131     warriors         4           due         4         free         1   \n",
       "132   initiation         4  conservation         4        throw         1   \n",
       "133        water         4          flow         4         line         1   \n",
       "134     specific         4        though         4            2         1   \n",
       "135      however         4    easterlies         4     naismith         1   \n",
       "136         once         4    tropopause         4     memorial         1   \n",
       "137     necklace         4  temperatures         4         1987         1   \n",
       "138        blood         4         north         4        would         1   \n",
       "139       elegu         4          even         4         well         1   \n",
       "\n",
       "            doc4  feq_doc4           doc5  feq_doc5  ...         doc16  \\\n",
       "0            the        25            the       612  ...           the   \n",
       "1         wanzer        15             of       191  ...           and   \n",
       "2              a         9             in       189  ...            in   \n",
       "3             in         9            and       173  ...            of   \n",
       "4            was         8             to       136  ...        menage   \n",
       "5            and         8              a       121  ...             a   \n",
       "6         royals         7    oktoberfest       105  ...            to   \n",
       "7             he         6             is        80  ...             s   \n",
       "8           hall         5            was        64  ...           was   \n",
       "9             to         5            for        55  ...            he   \n",
       "10        season         5                      55  ...           his   \n",
       "11            as         4           with        51  ...   minneapolis   \n",
       "12    basketball         4           beer        47  ...             1   \n",
       "13         coach         4       festival        47  ...           for   \n",
       "14            of         4             at        43  ...          with   \n",
       "15          with         4             on        41  ...          king   \n",
       "16           for         4             by        40  ...            by   \n",
       "17          also         3              s        39  ...          land   \n",
       "18            at         3          tents        39  ...          were   \n",
       "19         seton         3           tent        39  ...          real   \n",
       "20         after         3         munich        37  ...        estate   \n",
       "21          team         3             as        37  ...          city   \n",
       "22             1         3           from        36  ...     minnesota   \n",
       "23          star         3            are        36  ...            as   \n",
       "24          were         3           this        36  ...            at   \n",
       "25           nba         3          first        32  ...           had   \n",
       "26           his         3           were        26  ...           new   \n",
       "27            on         3             it        24  ...      business   \n",
       "28             4         2          which        24  ...          from   \n",
       "29       january         2             an        23  ...            on   \n",
       "..           ...       ...            ...       ...  ...           ...   \n",
       "110      195051         1              4         7  ...          much   \n",
       "111     national         1          today         7  ...       harriet   \n",
       "112  association         1        outside         7  ...        luxury   \n",
       "113        title         1          years         7  ...       tallest   \n",
       "114       entire         1           time         7  ...    skyscraper   \n",
       "115       career         1       citation         7  ...        battle   \n",
       "116     retiring         1             no         7  ...          over   \n",
       "117         play         1         police         7  ...          deal   \n",
       "118          end         1           2005         7  ...         panic   \n",
       "119         1957         1           2008         7  ...          1893   \n",
       "120     fivetime         1        smoking         7  ...          fled   \n",
       "121       allnba         1          small         7  ...         avoid   \n",
       "122       second         1            but         7  ...  embezzlement   \n",
       "123        three         1     historical         7  ...       dropped   \n",
       "124  consecutive         1     augustiner         7  ...           key   \n",
       "125        times         1         closed         7  ...     witnesses   \n",
       "126      195152         1           well         7  ...       testify   \n",
       "127         ever         1        germany         6  ...           him   \n",
       "128        shoot         1           name         6  ...         spent   \n",
       "129         over         1        example         6  ...       working   \n",
       "130           90         1        chicken         6  ...         never   \n",
       "131         free         1            now         6  ...        worked   \n",
       "132        throw         1             22         6  ...             5   \n",
       "133         line         1  restaurateurs         6  ...  philanthropy   \n",
       "134            2         1        costume         6  ...             6   \n",
       "135     naismith         1              7         6  ...      collapse   \n",
       "136     memorial         1         ludwig         6  ...             7   \n",
       "137         1987         1          races         6  ...         notes   \n",
       "138        would         1      tradition         6  ...             8   \n",
       "139         well         1        however         6  ...        father   \n",
       "\n",
       "     feq_doc16        doc17  feq_doc17              doc18  feq_doc18  \\\n",
       "0          106          the         80                the         18   \n",
       "1           56           in         57                and         16   \n",
       "2           55          she         35                 of         15   \n",
       "3           50          and         30                  a         14   \n",
       "4           49           of         22                 in         11   \n",
       "5           41         team         20             haston          7   \n",
       "6           39         ohea         16               book          5   \n",
       "7           26          for         16                 is          4   \n",
       "8           24          was         16             rising          4   \n",
       "9           24           at         15               dead          4   \n",
       "10          17            a         15               moon          4   \n",
       "11          15            3         15               echo          4   \n",
       "12          15         with         13            magical          4   \n",
       "13          15           to         13           whispers          4   \n",
       "14          14       season         13          published          4   \n",
       "15          13   australian         12                for          4   \n",
       "16          13         2012         11          elephants          4   \n",
       "17          12   basketball         11                  s          4   \n",
       "18          11     national         11                was          4   \n",
       "19          10          her         11                 to          4   \n",
       "20          10         game         10               from          3   \n",
       "21          10         wnbl          9            fiction          3   \n",
       "22           9       played          9         historical          3   \n",
       "23           8            s          7              blood          3   \n",
       "24           8       points          7              doves          3   \n",
       "25           8          per          7               2013          3   \n",
       "26           8        jenna          6                 an          3   \n",
       "27           8            2          6             career          3   \n",
       "28           7            4          6            october          3   \n",
       "29           7            6          6              class          3   \n",
       "..         ...          ...        ...                ...        ...   \n",
       "110          2  information          2               been          1   \n",
       "111          2    traralgon          2          augmented          1   \n",
       "112          2       listed          2             recent          1   \n",
       "113          2           lb          2              years          1   \n",
       "114          2           79          2                his          1   \n",
       "115          2       school          2              debut          1   \n",
       "116          2    caulfield          2              novel          1   \n",
       "117          2      grammar          2           followed          1   \n",
       "118          2      bendigo          2             almost          1   \n",
       "119          2       spirit          2  contemporaneously          1   \n",
       "120          2        arras          2              first          1   \n",
       "121          2          los          2          rewritten          1   \n",
       "122          2      angeles          2              final          1   \n",
       "123          2       sparks          2               form          1   \n",
       "124          2           2          2          september          1   \n",
       "125          2      allstar          2            spartan          1   \n",
       "126          2         hide          2              style          1   \n",
       "127          2  association          2               that          1   \n",
       "128          2           21          2              often          1   \n",
       "129          2           22          2           requires          1   \n",
       "130          2           23          2             reader          1   \n",
       "131          2     overseas          2            provide          1   \n",
       "132          2           on          2           linkages          1   \n",
       "133          2         luke          2             within          1   \n",
       "134          2         best          2              story          1   \n",
       "135          2     teammate          2               line          1   \n",
       "136          2  represented          2   characterisation          1   \n",
       "137          2          u16          2             themes          1   \n",
       "138          2          ais          2          suffering          1   \n",
       "139          2            7          2    underprivileged          1   \n",
       "\n",
       "            doc19  feq_doc19        doc20  feq_doc20  \n",
       "0             the        894          the        963  \n",
       "1              of        600           of        477  \n",
       "2              in        486         king        414  \n",
       "3             and        429          and        403  \n",
       "4        franklin        402           in        387  \n",
       "5               a        364           to        387  \n",
       "6              to        345            a        284  \n",
       "7             his        231         that        209  \n",
       "8              he        217          was        198  \n",
       "9             was        210            s        179  \n",
       "10           that        142          his        169  \n",
       "11             as        136           he        164  \n",
       "12              s        133          for        138  \n",
       "13             on        133           on        127  \n",
       "14            for        130         with        108  \n",
       "15             by        114           by         95  \n",
       "16           with         96            i         95  \n",
       "17           from         80       rights         83  \n",
       "18             it         64           as         82  \n",
       "19   philadelphia         59        civil         76  \n",
       "20       benjamin         58           at         71  \n",
       "21             an         58         from         66  \n",
       "22          which         58           an         65  \n",
       "23            had         55           it         60  \n",
       "24   pennsylvania         54          had         59  \n",
       "25             is         52         have         55  \n",
       "26             at         52           is         54  \n",
       "27          first         51        march         53  \n",
       "28       american         49       luther         52  \n",
       "29             be         47     movement         52  \n",
       "..            ...        ...          ...        ...  \n",
       "110          born         14        years         15  \n",
       "111          read         14         many         15  \n",
       "112    university         14         when         15  \n",
       "113     religious         14       school         15  \n",
       "114       college         14      however         15  \n",
       "115    electrical         14           my         15  \n",
       "116         named         14         both         15  \n",
       "117            15         14       social         15  \n",
       "118        father         14        party         15  \n",
       "119         three         14     southern         14  \n",
       "120           can         14    christian         14  \n",
       "121         these         14        april         14  \n",
       "122                      13       became         14  \n",
       "123    postmaster         13       called         14  \n",
       "124       general         13          new         14  \n",
       "125         early         13       police         14  \n",
       "126          work         13    americans         14  \n",
       "127        folger         13      because         14  \n",
       "128     published         13           up         14  \n",
       "129          over         13         main         14  \n",
       "130           see         12          say         14  \n",
       "131          john         12          are         14  \n",
       "132            17         12   birmingham         13  \n",
       "133         death         12        selma         13  \n",
       "134       deborah         12  nonviolence         13  \n",
       "135   electricity         12          has         13  \n",
       "136       several         12        could         13  \n",
       "137    scientific         12          any         13  \n",
       "138      national         12       before         13  \n",
       "139       britain         12        their         13  \n",
       "\n",
       "[140 rows x 42 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.concat([doc1,doc2,doc3,doc4,doc5,doc6,doc7,doc8,doc9,doc10\n",
    "              ,doc11,doc12,doc12,doc13,doc14,doc15,doc16,doc17,doc18\n",
    "              ,doc19,doc20], axis=1, join='inner')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.to_csv(r'doc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>doc1</th>\n",
       "      <th>feq_doc1</th>\n",
       "      <th>doc2</th>\n",
       "      <th>feq_doc2</th>\n",
       "      <th>doc3</th>\n",
       "      <th>feq_doc3</th>\n",
       "      <th>doc4</th>\n",
       "      <th>feq_doc4</th>\n",
       "      <th>doc5</th>\n",
       "      <th>...</th>\n",
       "      <th>doc16</th>\n",
       "      <th>feq_doc16</th>\n",
       "      <th>doc17</th>\n",
       "      <th>feq_doc17</th>\n",
       "      <th>doc18</th>\n",
       "      <th>feq_doc18</th>\n",
       "      <th>doc19</th>\n",
       "      <th>feq_doc19</th>\n",
       "      <th>doc20</th>\n",
       "      <th>feq_doc20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>273.0</td>\n",
       "      <td>the</td>\n",
       "      <td>322.0</td>\n",
       "      <td>the</td>\n",
       "      <td>25.0</td>\n",
       "      <td>the</td>\n",
       "      <td>25.0</td>\n",
       "      <td>the</td>\n",
       "      <td>...</td>\n",
       "      <td>the</td>\n",
       "      <td>106.0</td>\n",
       "      <td>the</td>\n",
       "      <td>80.0</td>\n",
       "      <td>the</td>\n",
       "      <td>18.0</td>\n",
       "      <td>the</td>\n",
       "      <td>894</td>\n",
       "      <td>the</td>\n",
       "      <td>963.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>138.0</td>\n",
       "      <td>of</td>\n",
       "      <td>111.0</td>\n",
       "      <td>wanzer</td>\n",
       "      <td>15.0</td>\n",
       "      <td>wanzer</td>\n",
       "      <td>15.0</td>\n",
       "      <td>of</td>\n",
       "      <td>...</td>\n",
       "      <td>and</td>\n",
       "      <td>56.0</td>\n",
       "      <td>in</td>\n",
       "      <td>57.0</td>\n",
       "      <td>and</td>\n",
       "      <td>16.0</td>\n",
       "      <td>of</td>\n",
       "      <td>600</td>\n",
       "      <td>of</td>\n",
       "      <td>477.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>and</td>\n",
       "      <td>123.0</td>\n",
       "      <td>and</td>\n",
       "      <td>91.0</td>\n",
       "      <td>a</td>\n",
       "      <td>9.0</td>\n",
       "      <td>a</td>\n",
       "      <td>9.0</td>\n",
       "      <td>in</td>\n",
       "      <td>...</td>\n",
       "      <td>in</td>\n",
       "      <td>55.0</td>\n",
       "      <td>she</td>\n",
       "      <td>35.0</td>\n",
       "      <td>of</td>\n",
       "      <td>15.0</td>\n",
       "      <td>in</td>\n",
       "      <td>486</td>\n",
       "      <td>king</td>\n",
       "      <td>414.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>84.0</td>\n",
       "      <td>a</td>\n",
       "      <td>57.0</td>\n",
       "      <td>in</td>\n",
       "      <td>9.0</td>\n",
       "      <td>in</td>\n",
       "      <td>9.0</td>\n",
       "      <td>and</td>\n",
       "      <td>...</td>\n",
       "      <td>of</td>\n",
       "      <td>50.0</td>\n",
       "      <td>and</td>\n",
       "      <td>30.0</td>\n",
       "      <td>a</td>\n",
       "      <td>14.0</td>\n",
       "      <td>and</td>\n",
       "      <td>429</td>\n",
       "      <td>and</td>\n",
       "      <td>403.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>to</td>\n",
       "      <td>81.0</td>\n",
       "      <td>in</td>\n",
       "      <td>56.0</td>\n",
       "      <td>was</td>\n",
       "      <td>8.0</td>\n",
       "      <td>was</td>\n",
       "      <td>8.0</td>\n",
       "      <td>to</td>\n",
       "      <td>...</td>\n",
       "      <td>menage</td>\n",
       "      <td>49.0</td>\n",
       "      <td>of</td>\n",
       "      <td>22.0</td>\n",
       "      <td>in</td>\n",
       "      <td>11.0</td>\n",
       "      <td>franklin</td>\n",
       "      <td>402</td>\n",
       "      <td>in</td>\n",
       "      <td>387.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 doc1  feq_doc1 doc2  feq_doc2    doc3  feq_doc3    doc4  \\\n",
       "0           0  the     273.0  the     322.0     the      25.0     the   \n",
       "1           1   of     138.0   of     111.0  wanzer      15.0  wanzer   \n",
       "2           2  and     123.0  and      91.0       a       9.0       a   \n",
       "3           3    a      84.0    a      57.0      in       9.0      in   \n",
       "4           4   to      81.0   in      56.0     was       8.0     was   \n",
       "\n",
       "   feq_doc4 doc5  ...   doc16 feq_doc16  doc17 feq_doc17  doc18 feq_doc18  \\\n",
       "0      25.0  the  ...     the     106.0    the      80.0    the      18.0   \n",
       "1      15.0   of  ...     and      56.0     in      57.0    and      16.0   \n",
       "2       9.0   in  ...      in      55.0    she      35.0     of      15.0   \n",
       "3       9.0  and  ...      of      50.0    and      30.0      a      14.0   \n",
       "4       8.0   to  ...  menage      49.0     of      22.0     in      11.0   \n",
       "\n",
       "      doc19 feq_doc19  doc20 feq_doc20  \n",
       "0       the       894    the     963.0  \n",
       "1        of       600     of     477.0  \n",
       "2        in       486   king     414.0  \n",
       "3       and       429    and     403.0  \n",
       "4  franklin       402     in     387.0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc=pd.read_csv('doc.csv')\n",
    "doc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>doc1</th>\n",
       "      <th>feq_doc1</th>\n",
       "      <th>doc2</th>\n",
       "      <th>feq_doc2</th>\n",
       "      <th>doc3</th>\n",
       "      <th>feq_doc3</th>\n",
       "      <th>doc4</th>\n",
       "      <th>feq_doc4</th>\n",
       "      <th>doc5</th>\n",
       "      <th>...</th>\n",
       "      <th>doc16</th>\n",
       "      <th>feq_doc16</th>\n",
       "      <th>doc17</th>\n",
       "      <th>feq_doc17</th>\n",
       "      <th>doc18</th>\n",
       "      <th>feq_doc18</th>\n",
       "      <th>doc19</th>\n",
       "      <th>feq_doc19</th>\n",
       "      <th>doc20</th>\n",
       "      <th>feq_doc20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>273.0</td>\n",
       "      <td>the</td>\n",
       "      <td>322.0</td>\n",
       "      <td>the</td>\n",
       "      <td>25.0</td>\n",
       "      <td>the</td>\n",
       "      <td>25.0</td>\n",
       "      <td>the</td>\n",
       "      <td>...</td>\n",
       "      <td>the</td>\n",
       "      <td>106.0</td>\n",
       "      <td>the</td>\n",
       "      <td>80.0</td>\n",
       "      <td>the</td>\n",
       "      <td>18.0</td>\n",
       "      <td>the</td>\n",
       "      <td>894</td>\n",
       "      <td>the</td>\n",
       "      <td>963.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>138.0</td>\n",
       "      <td>of</td>\n",
       "      <td>111.0</td>\n",
       "      <td>wanzer</td>\n",
       "      <td>15.0</td>\n",
       "      <td>wanzer</td>\n",
       "      <td>15.0</td>\n",
       "      <td>of</td>\n",
       "      <td>...</td>\n",
       "      <td>and</td>\n",
       "      <td>56.0</td>\n",
       "      <td>in</td>\n",
       "      <td>57.0</td>\n",
       "      <td>and</td>\n",
       "      <td>16.0</td>\n",
       "      <td>of</td>\n",
       "      <td>600</td>\n",
       "      <td>of</td>\n",
       "      <td>477.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>and</td>\n",
       "      <td>123.0</td>\n",
       "      <td>and</td>\n",
       "      <td>91.0</td>\n",
       "      <td>a</td>\n",
       "      <td>9.0</td>\n",
       "      <td>a</td>\n",
       "      <td>9.0</td>\n",
       "      <td>in</td>\n",
       "      <td>...</td>\n",
       "      <td>in</td>\n",
       "      <td>55.0</td>\n",
       "      <td>she</td>\n",
       "      <td>35.0</td>\n",
       "      <td>of</td>\n",
       "      <td>15.0</td>\n",
       "      <td>in</td>\n",
       "      <td>486</td>\n",
       "      <td>king</td>\n",
       "      <td>414.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>84.0</td>\n",
       "      <td>a</td>\n",
       "      <td>57.0</td>\n",
       "      <td>in</td>\n",
       "      <td>9.0</td>\n",
       "      <td>in</td>\n",
       "      <td>9.0</td>\n",
       "      <td>and</td>\n",
       "      <td>...</td>\n",
       "      <td>of</td>\n",
       "      <td>50.0</td>\n",
       "      <td>and</td>\n",
       "      <td>30.0</td>\n",
       "      <td>a</td>\n",
       "      <td>14.0</td>\n",
       "      <td>and</td>\n",
       "      <td>429</td>\n",
       "      <td>and</td>\n",
       "      <td>403.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>to</td>\n",
       "      <td>81.0</td>\n",
       "      <td>in</td>\n",
       "      <td>56.0</td>\n",
       "      <td>was</td>\n",
       "      <td>8.0</td>\n",
       "      <td>was</td>\n",
       "      <td>8.0</td>\n",
       "      <td>to</td>\n",
       "      <td>...</td>\n",
       "      <td>menage</td>\n",
       "      <td>49.0</td>\n",
       "      <td>of</td>\n",
       "      <td>22.0</td>\n",
       "      <td>in</td>\n",
       "      <td>11.0</td>\n",
       "      <td>franklin</td>\n",
       "      <td>402</td>\n",
       "      <td>in</td>\n",
       "      <td>387.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 doc1  feq_doc1 doc2  feq_doc2    doc3  feq_doc3    doc4  \\\n",
       "0           0  the     273.0  the     322.0     the      25.0     the   \n",
       "1           1   of     138.0   of     111.0  wanzer      15.0  wanzer   \n",
       "2           2  and     123.0  and      91.0       a       9.0       a   \n",
       "3           3    a      84.0    a      57.0      in       9.0      in   \n",
       "4           4   to      81.0   in      56.0     was       8.0     was   \n",
       "\n",
       "   feq_doc4 doc5  ...   doc16 feq_doc16  doc17 feq_doc17  doc18 feq_doc18  \\\n",
       "0      25.0  the  ...     the     106.0    the      80.0    the      18.0   \n",
       "1      15.0   of  ...     and      56.0     in      57.0    and      16.0   \n",
       "2       9.0   in  ...      in      55.0    she      35.0     of      15.0   \n",
       "3       9.0  and  ...      of      50.0    and      30.0      a      14.0   \n",
       "4       8.0   to  ...  menage      49.0     of      22.0     in      11.0   \n",
       "\n",
       "      doc19 feq_doc19  doc20 feq_doc20  \n",
       "0       the       894    the     963.0  \n",
       "1        of       600     of     477.0  \n",
       "2        in       486   king     414.0  \n",
       "3       and       429    and     403.0  \n",
       "4  franklin       402     in     387.0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.loc['sum'] = doc.sum()\n",
    "doc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.to_csv(r'doc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ real work "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF (Term Frequency)= (Number of time the word occurs in the text) / (Total number of words in text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IDF (Inverse Document Frequency)= (Total number of documents / Number of documents with word t in it)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF = TF * IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######\n",
    "\n",
    "1. \"tennis match\"\n",
    "2. \"88 thousand people!\"\n",
    "3. \"the plastic container; see <img src='drawing.jpg' alt=''>\"\n",
    "\n",
    "######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc= doc.fillna('-')\n",
    "#doc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.to_csv(r'doc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>doc1</th>\n",
       "      <th>feq_doc1</th>\n",
       "      <th>doc2</th>\n",
       "      <th>feq_doc2</th>\n",
       "      <th>doc3</th>\n",
       "      <th>feq_doc3</th>\n",
       "      <th>doc4</th>\n",
       "      <th>feq_doc4</th>\n",
       "      <th>...</th>\n",
       "      <th>doc16</th>\n",
       "      <th>feq_doc16</th>\n",
       "      <th>doc17</th>\n",
       "      <th>feq_doc17</th>\n",
       "      <th>doc18</th>\n",
       "      <th>feq_doc18</th>\n",
       "      <th>doc19</th>\n",
       "      <th>feq_doc19</th>\n",
       "      <th>doc20</th>\n",
       "      <th>feq_doc20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>273.0</td>\n",
       "      <td>the</td>\n",
       "      <td>322.0</td>\n",
       "      <td>the</td>\n",
       "      <td>25.0</td>\n",
       "      <td>the</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>the</td>\n",
       "      <td>106.0</td>\n",
       "      <td>the</td>\n",
       "      <td>80.0</td>\n",
       "      <td>the</td>\n",
       "      <td>18.0</td>\n",
       "      <td>the</td>\n",
       "      <td>894</td>\n",
       "      <td>the</td>\n",
       "      <td>963.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>138.0</td>\n",
       "      <td>of</td>\n",
       "      <td>111.0</td>\n",
       "      <td>wanzer</td>\n",
       "      <td>15.0</td>\n",
       "      <td>wanzer</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>and</td>\n",
       "      <td>56.0</td>\n",
       "      <td>in</td>\n",
       "      <td>57.0</td>\n",
       "      <td>and</td>\n",
       "      <td>16.0</td>\n",
       "      <td>of</td>\n",
       "      <td>600</td>\n",
       "      <td>of</td>\n",
       "      <td>477.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>and</td>\n",
       "      <td>123.0</td>\n",
       "      <td>and</td>\n",
       "      <td>91.0</td>\n",
       "      <td>a</td>\n",
       "      <td>9.0</td>\n",
       "      <td>a</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>in</td>\n",
       "      <td>55.0</td>\n",
       "      <td>she</td>\n",
       "      <td>35.0</td>\n",
       "      <td>of</td>\n",
       "      <td>15.0</td>\n",
       "      <td>in</td>\n",
       "      <td>486</td>\n",
       "      <td>king</td>\n",
       "      <td>414.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>84.0</td>\n",
       "      <td>a</td>\n",
       "      <td>57.0</td>\n",
       "      <td>in</td>\n",
       "      <td>9.0</td>\n",
       "      <td>in</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>of</td>\n",
       "      <td>50.0</td>\n",
       "      <td>and</td>\n",
       "      <td>30.0</td>\n",
       "      <td>a</td>\n",
       "      <td>14.0</td>\n",
       "      <td>and</td>\n",
       "      <td>429</td>\n",
       "      <td>and</td>\n",
       "      <td>403.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>to</td>\n",
       "      <td>81.0</td>\n",
       "      <td>in</td>\n",
       "      <td>56.0</td>\n",
       "      <td>was</td>\n",
       "      <td>8.0</td>\n",
       "      <td>was</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>menage</td>\n",
       "      <td>49.0</td>\n",
       "      <td>of</td>\n",
       "      <td>22.0</td>\n",
       "      <td>in</td>\n",
       "      <td>11.0</td>\n",
       "      <td>franklin</td>\n",
       "      <td>402</td>\n",
       "      <td>in</td>\n",
       "      <td>387.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>is</td>\n",
       "      <td>62.0</td>\n",
       "      <td>cell</td>\n",
       "      <td>54.0</td>\n",
       "      <td>and</td>\n",
       "      <td>8.0</td>\n",
       "      <td>and</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>a</td>\n",
       "      <td>41.0</td>\n",
       "      <td>team</td>\n",
       "      <td>20.0</td>\n",
       "      <td>haston</td>\n",
       "      <td>7.0</td>\n",
       "      <td>a</td>\n",
       "      <td>364</td>\n",
       "      <td>to</td>\n",
       "      <td>387.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>as</td>\n",
       "      <td>59.0</td>\n",
       "      <td>is</td>\n",
       "      <td>53.0</td>\n",
       "      <td>royals</td>\n",
       "      <td>7.0</td>\n",
       "      <td>royals</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>to</td>\n",
       "      <td>39.0</td>\n",
       "      <td>ohea</td>\n",
       "      <td>16.0</td>\n",
       "      <td>book</td>\n",
       "      <td>5.0</td>\n",
       "      <td>to</td>\n",
       "      <td>345</td>\n",
       "      <td>a</td>\n",
       "      <td>284.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>in</td>\n",
       "      <td>54.0</td>\n",
       "      <td>as</td>\n",
       "      <td>42.0</td>\n",
       "      <td>he</td>\n",
       "      <td>6.0</td>\n",
       "      <td>he</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>26.0</td>\n",
       "      <td>for</td>\n",
       "      <td>16.0</td>\n",
       "      <td>is</td>\n",
       "      <td>4.0</td>\n",
       "      <td>his</td>\n",
       "      <td>231</td>\n",
       "      <td>that</td>\n",
       "      <td>209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>that</td>\n",
       "      <td>41.0</td>\n",
       "      <td>air</td>\n",
       "      <td>41.0</td>\n",
       "      <td>hall</td>\n",
       "      <td>5.0</td>\n",
       "      <td>hall</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>was</td>\n",
       "      <td>24.0</td>\n",
       "      <td>was</td>\n",
       "      <td>16.0</td>\n",
       "      <td>rising</td>\n",
       "      <td>4.0</td>\n",
       "      <td>he</td>\n",
       "      <td>217</td>\n",
       "      <td>was</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>with</td>\n",
       "      <td>38.0</td>\n",
       "      <td>to</td>\n",
       "      <td>37.0</td>\n",
       "      <td>to</td>\n",
       "      <td>5.0</td>\n",
       "      <td>to</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>he</td>\n",
       "      <td>24.0</td>\n",
       "      <td>at</td>\n",
       "      <td>15.0</td>\n",
       "      <td>dead</td>\n",
       "      <td>4.0</td>\n",
       "      <td>was</td>\n",
       "      <td>210</td>\n",
       "      <td>s</td>\n",
       "      <td>179.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>or</td>\n",
       "      <td>32.0</td>\n",
       "      <td>at</td>\n",
       "      <td>34.0</td>\n",
       "      <td>season</td>\n",
       "      <td>5.0</td>\n",
       "      <td>season</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>his</td>\n",
       "      <td>17.0</td>\n",
       "      <td>a</td>\n",
       "      <td>15.0</td>\n",
       "      <td>moon</td>\n",
       "      <td>4.0</td>\n",
       "      <td>that</td>\n",
       "      <td>142</td>\n",
       "      <td>his</td>\n",
       "      <td>169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>are</td>\n",
       "      <td>31.0</td>\n",
       "      <td>it</td>\n",
       "      <td>33.0</td>\n",
       "      <td>as</td>\n",
       "      <td>4.0</td>\n",
       "      <td>as</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>minneapolis</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3</td>\n",
       "      <td>15.0</td>\n",
       "      <td>echo</td>\n",
       "      <td>4.0</td>\n",
       "      <td>as</td>\n",
       "      <td>136</td>\n",
       "      <td>he</td>\n",
       "      <td>164.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>santera</td>\n",
       "      <td>28.0</td>\n",
       "      <td>circulation</td>\n",
       "      <td>32.0</td>\n",
       "      <td>basketball</td>\n",
       "      <td>4.0</td>\n",
       "      <td>basketball</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>with</td>\n",
       "      <td>13.0</td>\n",
       "      <td>magical</td>\n",
       "      <td>4.0</td>\n",
       "      <td>s</td>\n",
       "      <td>133</td>\n",
       "      <td>for</td>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>be</td>\n",
       "      <td>24.0</td>\n",
       "      <td>are</td>\n",
       "      <td>32.0</td>\n",
       "      <td>coach</td>\n",
       "      <td>4.0</td>\n",
       "      <td>coach</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>for</td>\n",
       "      <td>15.0</td>\n",
       "      <td>to</td>\n",
       "      <td>13.0</td>\n",
       "      <td>whispers</td>\n",
       "      <td>4.0</td>\n",
       "      <td>on</td>\n",
       "      <td>133</td>\n",
       "      <td>on</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>for</td>\n",
       "      <td>23.0</td>\n",
       "      <td>hadley</td>\n",
       "      <td>31.0</td>\n",
       "      <td>of</td>\n",
       "      <td>4.0</td>\n",
       "      <td>of</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>with</td>\n",
       "      <td>14.0</td>\n",
       "      <td>season</td>\n",
       "      <td>13.0</td>\n",
       "      <td>published</td>\n",
       "      <td>4.0</td>\n",
       "      <td>for</td>\n",
       "      <td>130</td>\n",
       "      <td>with</td>\n",
       "      <td>108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>their</td>\n",
       "      <td>23.0</td>\n",
       "      <td>polar</td>\n",
       "      <td>29.0</td>\n",
       "      <td>with</td>\n",
       "      <td>4.0</td>\n",
       "      <td>with</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>king</td>\n",
       "      <td>13.0</td>\n",
       "      <td>australian</td>\n",
       "      <td>12.0</td>\n",
       "      <td>for</td>\n",
       "      <td>4.0</td>\n",
       "      <td>by</td>\n",
       "      <td>114</td>\n",
       "      <td>by</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>by</td>\n",
       "      <td>21.0</td>\n",
       "      <td>by</td>\n",
       "      <td>27.0</td>\n",
       "      <td>for</td>\n",
       "      <td>4.0</td>\n",
       "      <td>for</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>by</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>11.0</td>\n",
       "      <td>elephants</td>\n",
       "      <td>4.0</td>\n",
       "      <td>with</td>\n",
       "      <td>96</td>\n",
       "      <td>i</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>orichs</td>\n",
       "      <td>21.0</td>\n",
       "      <td>ferrel</td>\n",
       "      <td>27.0</td>\n",
       "      <td>also</td>\n",
       "      <td>3.0</td>\n",
       "      <td>also</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>land</td>\n",
       "      <td>12.0</td>\n",
       "      <td>basketball</td>\n",
       "      <td>11.0</td>\n",
       "      <td>s</td>\n",
       "      <td>4.0</td>\n",
       "      <td>from</td>\n",
       "      <td>80</td>\n",
       "      <td>rights</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>known</td>\n",
       "      <td>19.0</td>\n",
       "      <td>that</td>\n",
       "      <td>25.0</td>\n",
       "      <td>at</td>\n",
       "      <td>3.0</td>\n",
       "      <td>at</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>were</td>\n",
       "      <td>11.0</td>\n",
       "      <td>national</td>\n",
       "      <td>11.0</td>\n",
       "      <td>was</td>\n",
       "      <td>4.0</td>\n",
       "      <td>it</td>\n",
       "      <td>64</td>\n",
       "      <td>as</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>traditional</td>\n",
       "      <td>19.0</td>\n",
       "      <td>surface</td>\n",
       "      <td>22.0</td>\n",
       "      <td>seton</td>\n",
       "      <td>3.0</td>\n",
       "      <td>seton</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>real</td>\n",
       "      <td>10.0</td>\n",
       "      <td>her</td>\n",
       "      <td>11.0</td>\n",
       "      <td>to</td>\n",
       "      <td>4.0</td>\n",
       "      <td>philadelphia</td>\n",
       "      <td>59</td>\n",
       "      <td>civil</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>from</td>\n",
       "      <td>19.0</td>\n",
       "      <td>cells</td>\n",
       "      <td>18.0</td>\n",
       "      <td>after</td>\n",
       "      <td>3.0</td>\n",
       "      <td>after</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>estate</td>\n",
       "      <td>10.0</td>\n",
       "      <td>game</td>\n",
       "      <td>10.0</td>\n",
       "      <td>from</td>\n",
       "      <td>3.0</td>\n",
       "      <td>benjamin</td>\n",
       "      <td>58</td>\n",
       "      <td>at</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>healing</td>\n",
       "      <td>17.0</td>\n",
       "      <td>this</td>\n",
       "      <td>17.0</td>\n",
       "      <td>team</td>\n",
       "      <td>3.0</td>\n",
       "      <td>team</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>city</td>\n",
       "      <td>10.0</td>\n",
       "      <td>wnbl</td>\n",
       "      <td>9.0</td>\n",
       "      <td>fiction</td>\n",
       "      <td>3.0</td>\n",
       "      <td>an</td>\n",
       "      <td>58</td>\n",
       "      <td>from</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>17.0</td>\n",
       "      <td>pacific</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>minnesota</td>\n",
       "      <td>9.0</td>\n",
       "      <td>played</td>\n",
       "      <td>9.0</td>\n",
       "      <td>historical</td>\n",
       "      <td>3.0</td>\n",
       "      <td>which</td>\n",
       "      <td>58</td>\n",
       "      <td>an</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>an</td>\n",
       "      <td>16.0</td>\n",
       "      <td>from</td>\n",
       "      <td>16.0</td>\n",
       "      <td>star</td>\n",
       "      <td>3.0</td>\n",
       "      <td>star</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>as</td>\n",
       "      <td>8.0</td>\n",
       "      <td>s</td>\n",
       "      <td>7.0</td>\n",
       "      <td>blood</td>\n",
       "      <td>3.0</td>\n",
       "      <td>had</td>\n",
       "      <td>55</td>\n",
       "      <td>it</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>also</td>\n",
       "      <td>15.0</td>\n",
       "      <td>on</td>\n",
       "      <td>16.0</td>\n",
       "      <td>were</td>\n",
       "      <td>3.0</td>\n",
       "      <td>were</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>at</td>\n",
       "      <td>8.0</td>\n",
       "      <td>points</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doves</td>\n",
       "      <td>3.0</td>\n",
       "      <td>pennsylvania</td>\n",
       "      <td>54</td>\n",
       "      <td>had</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>they</td>\n",
       "      <td>15.0</td>\n",
       "      <td>s</td>\n",
       "      <td>16.0</td>\n",
       "      <td>nba</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nba</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>had</td>\n",
       "      <td>8.0</td>\n",
       "      <td>per</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>3.0</td>\n",
       "      <td>is</td>\n",
       "      <td>52</td>\n",
       "      <td>have</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>on</td>\n",
       "      <td>14.0</td>\n",
       "      <td>which</td>\n",
       "      <td>16.0</td>\n",
       "      <td>his</td>\n",
       "      <td>3.0</td>\n",
       "      <td>his</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>new</td>\n",
       "      <td>8.0</td>\n",
       "      <td>jenna</td>\n",
       "      <td>6.0</td>\n",
       "      <td>an</td>\n",
       "      <td>3.0</td>\n",
       "      <td>at</td>\n",
       "      <td>52</td>\n",
       "      <td>is</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>orich</td>\n",
       "      <td>14.0</td>\n",
       "      <td>equator</td>\n",
       "      <td>14.0</td>\n",
       "      <td>on</td>\n",
       "      <td>3.0</td>\n",
       "      <td>on</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>business</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>career</td>\n",
       "      <td>3.0</td>\n",
       "      <td>first</td>\n",
       "      <td>51</td>\n",
       "      <td>march</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>which</td>\n",
       "      <td>14.0</td>\n",
       "      <td>winds</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>from</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>october</td>\n",
       "      <td>3.0</td>\n",
       "      <td>american</td>\n",
       "      <td>49</td>\n",
       "      <td>luther</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>religion</td>\n",
       "      <td>12.0</td>\n",
       "      <td>toward</td>\n",
       "      <td>14.0</td>\n",
       "      <td>january</td>\n",
       "      <td>2.0</td>\n",
       "      <td>january</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>on</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>class</td>\n",
       "      <td>3.0</td>\n",
       "      <td>be</td>\n",
       "      <td>47</td>\n",
       "      <td>movement</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3733</th>\n",
       "      <td>3733</td>\n",
       "      <td>3733</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>cv13</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3734</th>\n",
       "      <td>3734</td>\n",
       "      <td>3734</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>bon</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3735</th>\n",
       "      <td>3735</td>\n",
       "      <td>3735</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>homme</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3736</th>\n",
       "      <td>3736</td>\n",
       "      <td>3736</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>cv31</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3737</th>\n",
       "      <td>3737</td>\n",
       "      <td>3737</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>operation</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3738</th>\n",
       "      <td>3738</td>\n",
       "      <td>3738</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>ii</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3739</th>\n",
       "      <td>3739</td>\n",
       "      <td>3739</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>distinction</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3740</th>\n",
       "      <td>3740</td>\n",
       "      <td>3740</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>operational</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3741</th>\n",
       "      <td>3741</td>\n",
       "      <td>3741</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1797</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3742</th>\n",
       "      <td>3742</td>\n",
       "      <td>3742</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>franklinia</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3743</th>\n",
       "      <td>3743</td>\n",
       "      <td>3743</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>alatamaha</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3744</th>\n",
       "      <td>3744</td>\n",
       "      <td>3744</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>tree</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3745</th>\n",
       "      <td>3745</td>\n",
       "      <td>3745</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>philadelphians</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3746</th>\n",
       "      <td>3746</td>\n",
       "      <td>3746</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>botanists</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3747</th>\n",
       "      <td>3747</td>\n",
       "      <td>3747</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>bartram</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3748</th>\n",
       "      <td>3748</td>\n",
       "      <td>3748</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>cma</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749</th>\n",
       "      <td>3749</td>\n",
       "      <td>3749</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>cgm</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3750</th>\n",
       "      <td>3750</td>\n",
       "      <td>3750</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>chinesebuilt</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3751</th>\n",
       "      <td>3751</td>\n",
       "      <td>3751</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>explorerclass</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3752</th>\n",
       "      <td>3752</td>\n",
       "      <td>3752</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>container</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3753</th>\n",
       "      <td>3753</td>\n",
       "      <td>3753</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3754</th>\n",
       "      <td>3754</td>\n",
       "      <td>3754</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>mayhew</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3755</th>\n",
       "      <td>3755</td>\n",
       "      <td>3755</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>assistant</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3756</th>\n",
       "      <td>3756</td>\n",
       "      <td>3756</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>15th</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3757</th>\n",
       "      <td>3757</td>\n",
       "      <td>3757</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>fled</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3758</th>\n",
       "      <td>3758</td>\n",
       "      <td>3758</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>purified</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3759</th>\n",
       "      <td>3759</td>\n",
       "      <td>3759</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>congregationalist</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3760</th>\n",
       "      <td>3760</td>\n",
       "      <td>3760</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>christianity</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3761</th>\n",
       "      <td>3761</td>\n",
       "      <td>3761</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>194</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3762</th>\n",
       "      <td>sum</td>\n",
       "      <td>7074441</td>\n",
       "      <td>-</td>\n",
       "      <td>3477.0</td>\n",
       "      <td>-</td>\n",
       "      <td>2944.0</td>\n",
       "      <td>-</td>\n",
       "      <td>339.0</td>\n",
       "      <td>-</td>\n",
       "      <td>339.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>1657.0</td>\n",
       "      <td>-</td>\n",
       "      <td>1172.0</td>\n",
       "      <td>-</td>\n",
       "      <td>339.0</td>\n",
       "      <td>theofinandfranklinatohishewasthatassonforbywit...</td>\n",
       "      <td>15361</td>\n",
       "      <td>-</td>\n",
       "      <td>15178.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3763 rows  44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  Unnamed: 0.1         doc1 feq_doc1         doc2 feq_doc2  \\\n",
       "0             0             0          the    273.0          the    322.0   \n",
       "1             1             1           of    138.0           of    111.0   \n",
       "2             2             2          and    123.0          and     91.0   \n",
       "3             3             3            a     84.0            a     57.0   \n",
       "4             4             4           to     81.0           in     56.0   \n",
       "5             5             5           is     62.0         cell     54.0   \n",
       "6             6             6           as     59.0           is     53.0   \n",
       "7             7             7           in     54.0           as     42.0   \n",
       "8             8             8         that     41.0          air     41.0   \n",
       "9             9             9         with     38.0           to     37.0   \n",
       "10           10            10           or     32.0           at     34.0   \n",
       "11           11            11          are     31.0           it     33.0   \n",
       "12           12            12     santera     28.0  circulation     32.0   \n",
       "13           13            13           be     24.0          are     32.0   \n",
       "14           14            14          for     23.0       hadley     31.0   \n",
       "15           15            15        their     23.0        polar     29.0   \n",
       "16           16            16           by     21.0           by     27.0   \n",
       "17           17            17      orichs     21.0       ferrel     27.0   \n",
       "18           18            18        known     19.0         that     25.0   \n",
       "19           19            19  traditional     19.0      surface     22.0   \n",
       "20           20            20         from     19.0        cells     18.0   \n",
       "21           21            21      healing     17.0         this     17.0   \n",
       "22           22            22            6     17.0      pacific     17.0   \n",
       "23           23            23           an     16.0         from     16.0   \n",
       "24           24            24         also     15.0           on     16.0   \n",
       "25           25            25         they     15.0            s     16.0   \n",
       "26           26            26           on     14.0        which     16.0   \n",
       "27           27            27       orich     14.0      equator     14.0   \n",
       "28           28            28        which     14.0        winds     14.0   \n",
       "29           29            29     religion     12.0       toward     14.0   \n",
       "...         ...           ...          ...      ...          ...      ...   \n",
       "3733       3733          3733            -        -            -        -   \n",
       "3734       3734          3734            -        -            -        -   \n",
       "3735       3735          3735            -        -            -        -   \n",
       "3736       3736          3736            -        -            -        -   \n",
       "3737       3737          3737            -        -            -        -   \n",
       "3738       3738          3738            -        -            -        -   \n",
       "3739       3739          3739            -        -            -        -   \n",
       "3740       3740          3740            -        -            -        -   \n",
       "3741       3741          3741            -        -            -        -   \n",
       "3742       3742          3742            -        -            -        -   \n",
       "3743       3743          3743            -        -            -        -   \n",
       "3744       3744          3744            -        -            -        -   \n",
       "3745       3745          3745            -        -            -        -   \n",
       "3746       3746          3746            -        -            -        -   \n",
       "3747       3747          3747            -        -            -        -   \n",
       "3748       3748          3748            -        -            -        -   \n",
       "3749       3749          3749            -        -            -        -   \n",
       "3750       3750          3750            -        -            -        -   \n",
       "3751       3751          3751            -        -            -        -   \n",
       "3752       3752          3752            -        -            -        -   \n",
       "3753       3753          3753            -        -            -        -   \n",
       "3754       3754          3754            -        -            -        -   \n",
       "3755       3755          3755            -        -            -        -   \n",
       "3756       3756          3756            -        -            -        -   \n",
       "3757       3757          3757            -        -            -        -   \n",
       "3758       3758          3758            -        -            -        -   \n",
       "3759       3759          3759            -        -            -        -   \n",
       "3760       3760          3760            -        -            -        -   \n",
       "3761       3761          3761            -        -            -        -   \n",
       "3762        sum       7074441            -   3477.0            -   2944.0   \n",
       "\n",
       "            doc3 feq_doc3        doc4 feq_doc4  ...        doc16 feq_doc16  \\\n",
       "0            the     25.0         the     25.0  ...          the     106.0   \n",
       "1         wanzer     15.0      wanzer     15.0  ...          and      56.0   \n",
       "2              a      9.0           a      9.0  ...           in      55.0   \n",
       "3             in      9.0          in      9.0  ...           of      50.0   \n",
       "4            was      8.0         was      8.0  ...       menage      49.0   \n",
       "5            and      8.0         and      8.0  ...            a      41.0   \n",
       "6         royals      7.0      royals      7.0  ...           to      39.0   \n",
       "7             he      6.0          he      6.0  ...            s      26.0   \n",
       "8           hall      5.0        hall      5.0  ...          was      24.0   \n",
       "9             to      5.0          to      5.0  ...           he      24.0   \n",
       "10        season      5.0      season      5.0  ...          his      17.0   \n",
       "11            as      4.0          as      4.0  ...  minneapolis      15.0   \n",
       "12    basketball      4.0  basketball      4.0  ...            1      15.0   \n",
       "13         coach      4.0       coach      4.0  ...          for      15.0   \n",
       "14            of      4.0          of      4.0  ...         with      14.0   \n",
       "15          with      4.0        with      4.0  ...         king      13.0   \n",
       "16           for      4.0         for      4.0  ...           by      13.0   \n",
       "17          also      3.0        also      3.0  ...         land      12.0   \n",
       "18            at      3.0          at      3.0  ...         were      11.0   \n",
       "19         seton      3.0       seton      3.0  ...         real      10.0   \n",
       "20         after      3.0       after      3.0  ...       estate      10.0   \n",
       "21          team      3.0        team      3.0  ...         city      10.0   \n",
       "22             1      3.0           1      3.0  ...    minnesota       9.0   \n",
       "23          star      3.0        star      3.0  ...           as       8.0   \n",
       "24          were      3.0        were      3.0  ...           at       8.0   \n",
       "25           nba      3.0         nba      3.0  ...          had       8.0   \n",
       "26           his      3.0         his      3.0  ...          new       8.0   \n",
       "27            on      3.0          on      3.0  ...     business       8.0   \n",
       "28             4      2.0           4      2.0  ...         from       7.0   \n",
       "29       january      2.0     january      2.0  ...           on       7.0   \n",
       "...          ...      ...         ...      ...  ...          ...       ...   \n",
       "3733           -        -           -        -  ...            -         -   \n",
       "3734           -        -           -        -  ...            -         -   \n",
       "3735           -        -           -        -  ...            -         -   \n",
       "3736           -        -           -        -  ...            -         -   \n",
       "3737           -        -           -        -  ...            -         -   \n",
       "3738           -        -           -        -  ...            -         -   \n",
       "3739           -        -           -        -  ...            -         -   \n",
       "3740           -        -           -        -  ...            -         -   \n",
       "3741           -        -           -        -  ...            -         -   \n",
       "3742           -        -           -        -  ...            -         -   \n",
       "3743           -        -           -        -  ...            -         -   \n",
       "3744           -        -           -        -  ...            -         -   \n",
       "3745           -        -           -        -  ...            -         -   \n",
       "3746           -        -           -        -  ...            -         -   \n",
       "3747           -        -           -        -  ...            -         -   \n",
       "3748           -        -           -        -  ...            -         -   \n",
       "3749           -        -           -        -  ...            -         -   \n",
       "3750           -        -           -        -  ...            -         -   \n",
       "3751           -        -           -        -  ...            -         -   \n",
       "3752           -        -           -        -  ...            -         -   \n",
       "3753           -        -           -        -  ...            -         -   \n",
       "3754           -        -           -        -  ...            -         -   \n",
       "3755           -        -           -        -  ...            -         -   \n",
       "3756           -        -           -        -  ...            -         -   \n",
       "3757           -        -           -        -  ...            -         -   \n",
       "3758           -        -           -        -  ...            -         -   \n",
       "3759           -        -           -        -  ...            -         -   \n",
       "3760           -        -           -        -  ...            -         -   \n",
       "3761           -        -           -        -  ...            -         -   \n",
       "3762           -    339.0           -    339.0  ...            -    1657.0   \n",
       "\n",
       "           doc17 feq_doc17       doc18 feq_doc18  \\\n",
       "0            the      80.0         the      18.0   \n",
       "1             in      57.0         and      16.0   \n",
       "2            she      35.0          of      15.0   \n",
       "3            and      30.0           a      14.0   \n",
       "4             of      22.0          in      11.0   \n",
       "5           team      20.0      haston       7.0   \n",
       "6           ohea      16.0        book       5.0   \n",
       "7            for      16.0          is       4.0   \n",
       "8            was      16.0      rising       4.0   \n",
       "9             at      15.0        dead       4.0   \n",
       "10             a      15.0        moon       4.0   \n",
       "11             3      15.0        echo       4.0   \n",
       "12          with      13.0     magical       4.0   \n",
       "13            to      13.0    whispers       4.0   \n",
       "14        season      13.0   published       4.0   \n",
       "15    australian      12.0         for       4.0   \n",
       "16          2012      11.0   elephants       4.0   \n",
       "17    basketball      11.0           s       4.0   \n",
       "18      national      11.0         was       4.0   \n",
       "19           her      11.0          to       4.0   \n",
       "20          game      10.0        from       3.0   \n",
       "21          wnbl       9.0     fiction       3.0   \n",
       "22        played       9.0  historical       3.0   \n",
       "23             s       7.0       blood       3.0   \n",
       "24        points       7.0       doves       3.0   \n",
       "25           per       7.0        2013       3.0   \n",
       "26         jenna       6.0          an       3.0   \n",
       "27             2       6.0      career       3.0   \n",
       "28             4       6.0     october       3.0   \n",
       "29             6       6.0       class       3.0   \n",
       "...          ...       ...         ...       ...   \n",
       "3733           -         -           -         -   \n",
       "3734           -         -           -         -   \n",
       "3735           -         -           -         -   \n",
       "3736           -         -           -         -   \n",
       "3737           -         -           -         -   \n",
       "3738           -         -           -         -   \n",
       "3739           -         -           -         -   \n",
       "3740           -         -           -         -   \n",
       "3741           -         -           -         -   \n",
       "3742           -         -           -         -   \n",
       "3743           -         -           -         -   \n",
       "3744           -         -           -         -   \n",
       "3745           -         -           -         -   \n",
       "3746           -         -           -         -   \n",
       "3747           -         -           -         -   \n",
       "3748           -         -           -         -   \n",
       "3749           -         -           -         -   \n",
       "3750           -         -           -         -   \n",
       "3751           -         -           -         -   \n",
       "3752           -         -           -         -   \n",
       "3753           -         -           -         -   \n",
       "3754           -         -           -         -   \n",
       "3755           -         -           -         -   \n",
       "3756           -         -           -         -   \n",
       "3757           -         -           -         -   \n",
       "3758           -         -           -         -   \n",
       "3759           -         -           -         -   \n",
       "3760           -         -           -         -   \n",
       "3761           -         -           -         -   \n",
       "3762           -    1172.0           -     339.0   \n",
       "\n",
       "                                                  doc19 feq_doc19     doc20  \\\n",
       "0                                                   the       894       the   \n",
       "1                                                    of       600        of   \n",
       "2                                                    in       486      king   \n",
       "3                                                   and       429       and   \n",
       "4                                              franklin       402        in   \n",
       "5                                                     a       364        to   \n",
       "6                                                    to       345         a   \n",
       "7                                                   his       231      that   \n",
       "8                                                    he       217       was   \n",
       "9                                                   was       210         s   \n",
       "10                                                 that       142       his   \n",
       "11                                                   as       136        he   \n",
       "12                                                    s       133       for   \n",
       "13                                                   on       133        on   \n",
       "14                                                  for       130      with   \n",
       "15                                                   by       114        by   \n",
       "16                                                 with        96         i   \n",
       "17                                                 from        80    rights   \n",
       "18                                                   it        64        as   \n",
       "19                                         philadelphia        59     civil   \n",
       "20                                             benjamin        58        at   \n",
       "21                                                   an        58      from   \n",
       "22                                                which        58        an   \n",
       "23                                                  had        55        it   \n",
       "24                                         pennsylvania        54       had   \n",
       "25                                                   is        52      have   \n",
       "26                                                   at        52        is   \n",
       "27                                                first        51     march   \n",
       "28                                             american        49    luther   \n",
       "29                                                   be        47  movement   \n",
       "...                                                 ...       ...       ...   \n",
       "3733                                               cv13         1         -   \n",
       "3734                                                bon         1         -   \n",
       "3735                                              homme         1         -   \n",
       "3736                                               cv31         1         -   \n",
       "3737                                          operation         1         -   \n",
       "3738                                                 ii         1         -   \n",
       "3739                                        distinction         1         -   \n",
       "3740                                        operational         1         -   \n",
       "3741                                               1797         1         -   \n",
       "3742                                         franklinia         1         -   \n",
       "3743                                          alatamaha         1         -   \n",
       "3744                                               tree         1         -   \n",
       "3745                                     philadelphians         1         -   \n",
       "3746                                          botanists         1         -   \n",
       "3747                                            bartram         1         -   \n",
       "3748                                                cma         1         -   \n",
       "3749                                                cgm         1         -   \n",
       "3750                                       chinesebuilt         1         -   \n",
       "3751                                      explorerclass         1         -   \n",
       "3752                                          container         1         -   \n",
       "3753                                                193         1         -   \n",
       "3754                                             mayhew         1         -   \n",
       "3755                                          assistant         1         -   \n",
       "3756                                               15th         1         -   \n",
       "3757                                               fled         1         -   \n",
       "3758                                           purified         1         -   \n",
       "3759                                  congregationalist         1         -   \n",
       "3760                                       christianity         1         -   \n",
       "3761                                                194         1         -   \n",
       "3762  theofinandfranklinatohishewasthatassonforbywit...     15361         -   \n",
       "\n",
       "     feq_doc20  \n",
       "0        963.0  \n",
       "1        477.0  \n",
       "2        414.0  \n",
       "3        403.0  \n",
       "4        387.0  \n",
       "5        387.0  \n",
       "6        284.0  \n",
       "7        209.0  \n",
       "8        198.0  \n",
       "9        179.0  \n",
       "10       169.0  \n",
       "11       164.0  \n",
       "12       138.0  \n",
       "13       127.0  \n",
       "14       108.0  \n",
       "15        95.0  \n",
       "16        95.0  \n",
       "17        83.0  \n",
       "18        82.0  \n",
       "19        76.0  \n",
       "20        71.0  \n",
       "21        66.0  \n",
       "22        65.0  \n",
       "23        60.0  \n",
       "24        59.0  \n",
       "25        55.0  \n",
       "26        54.0  \n",
       "27        53.0  \n",
       "28        52.0  \n",
       "29        52.0  \n",
       "...        ...  \n",
       "3733         -  \n",
       "3734         -  \n",
       "3735         -  \n",
       "3736         -  \n",
       "3737         -  \n",
       "3738         -  \n",
       "3739         -  \n",
       "3740         -  \n",
       "3741         -  \n",
       "3742         -  \n",
       "3743         -  \n",
       "3744         -  \n",
       "3745         -  \n",
       "3746         -  \n",
       "3747         -  \n",
       "3748         -  \n",
       "3749         -  \n",
       "3750         -  \n",
       "3751         -  \n",
       "3752         -  \n",
       "3753         -  \n",
       "3754         -  \n",
       "3755         -  \n",
       "3756         -  \n",
       "3757         -  \n",
       "3758         -  \n",
       "3759         -  \n",
       "3760         -  \n",
       "3761         -  \n",
       "3762   15178.0  \n",
       "\n",
       "[3763 rows x 44 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = pd.read_csv('doc.csv')\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-fc137cc79475>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'the'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5065\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5066\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5067\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5069\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'str'"
     ]
    }
   ],
   "source": [
    "\n",
    "doc[doc.str.match('the')]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
