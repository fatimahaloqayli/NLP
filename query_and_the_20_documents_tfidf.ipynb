{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "filename = 'documents/document_1.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "#print (text)\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "# filter out stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = [w for w in stripped if not w in stop_words]\n",
    "\n",
    "bad_chars = [';', ':', '!', \"*\", '%','#','@','←','→','∞','“','”','’','=','>','.','—'] \n",
    "# using replace() to  \n",
    "# remove bad_chars  \n",
    "# remove bad_chars  \n",
    "test_string = filter(lambda i: i not in bad_chars, words)\n",
    "    \n",
    "d1 = list(filter(None,test_string))\n",
    "#print(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  load data\n",
    "filename = 'documents/document_2.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "#print (text)\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "# filter out stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = [w for w in stripped if not w in stop_words]\n",
    "\n",
    "bad_chars = [';', ':', '!', \"*\", '%','#','@','←','→','∞','“','”','’','=','>','.','—'] \n",
    " \n",
    "# remove bad_chars  \n",
    "test_string = filter(lambda i: i not in bad_chars, words)\n",
    "\n",
    "d2 = list(filter(None,test_string))\n",
    "#print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  load data\n",
    "filename = 'documents/document_3.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "#print (text)\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "# filter out stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = [w for w in stripped if not w in stop_words]\n",
    "\n",
    "bad_chars = [';', ':', '!', \"*\", '%','#','@','←','→','∞','“','”','’','=','>','.','—'] \n",
    " \n",
    "# remove bad_chars  \n",
    "test_string = filter(lambda i: i not in bad_chars, words)\n",
    "\n",
    "d3 = list(filter(None,test_string))\n",
    "#print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "filename = 'documents/document_4.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "#print (text)\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "# filter out stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = [w for w in stripped if not w in stop_words]\n",
    "\n",
    "bad_chars = [';', ':', '!', \"*\", '%','#','@','←','→','∞','“','”','’','=','>','.','—'] \n",
    " \n",
    "# remove bad_chars  \n",
    "test_string = filter(lambda i: i not in bad_chars, words)\n",
    "\n",
    "\n",
    "\n",
    "d4 = list(filter(None,test_string))\n",
    "#print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "filename = 'documents/document_5.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "#print (text)\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "# filter out stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = [w for w in stripped if not w in stop_words]\n",
    "\n",
    "bad_chars = [';', ':', '!', \"*\", '%','#','@','←','→','∞','“','”','’','=','>','.','—'] \n",
    " \n",
    "# remove bad_chars  \n",
    "test_string = filter(lambda i: i not in bad_chars, words)\n",
    "\n",
    "\n",
    "\n",
    "d5= list(filter(None,test_string))\n",
    "#print(w)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "filename = 'documents/document_6.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "#print (text)\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "# filter out stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = [w for w in stripped if not w in stop_words]\n",
    "\n",
    "bad_chars = [';', ':', '!', \"*\", '%','#','@','←','→','∞','“','”','’','=','>','.','—'] \n",
    " \n",
    "# remove bad_chars  \n",
    "test_string = filter(lambda i: i not in bad_chars, words)\n",
    "\n",
    "d6= list(filter(None,test_string))\n",
    "#print(w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "filename = 'documents/document_7.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "#print (text)\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "# filter out stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = [w for w in stripped if not w in stop_words]\n",
    "\n",
    "bad_chars = [';', ':', '!', \"*\", '%','#','@','←','→','∞','“','”','’','=','>','.','—'] \n",
    " \n",
    "# remove bad_chars  \n",
    "test_string = filter(lambda i: i not in bad_chars, words)\n",
    "\n",
    "\n",
    "d7 = list(filter(None,test_string))\n",
    "#print(w)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "filename = 'documents/document_8.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "#print (text)\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "# filter out stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = [w for w in stripped if not w in stop_words]\n",
    "\n",
    "bad_chars = [';', ':', '!', \"*\", '%','#','@','←','→','∞','“','”','’','=','>','.','—'] \n",
    " \n",
    "# remove bad_chars  \n",
    "test_string = filter(lambda i: i not in bad_chars, words)\n",
    "\n",
    "\n",
    "d8 = list(filter(None,test_string))\n",
    "#print(w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "filename = 'documents/document_9.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "#print (text)\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "# filter out stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = [w for w in stripped if not w in stop_words]\n",
    "\n",
    "bad_chars = [';', ':', '!', \"*\", '%','#','@','←','→','∞','“','”','’','=','>','.','—'] \n",
    " \n",
    "# remove bad_chars  \n",
    "test_string = filter(lambda i: i not in bad_chars, words)\n",
    "\n",
    "d9 = list(filter(None,test_string))\n",
    "#print(w)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "filename = 'documents/document_10.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "#print (text)\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "# filter out stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = [w for w in stripped if not w in stop_words]\n",
    "\n",
    "bad_chars = [';', ':', '!', \"*\", '%','#','@','←','→','∞','“','”','’','=','>','.','—'] \n",
    " \n",
    "# remove bad_chars  \n",
    "test_string = filter(lambda i: i not in bad_chars, words)\n",
    "\n",
    "\n",
    "d10= list(filter(None,test_string))\n",
    "#print(w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "filename = 'documents/document_11.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "#print (text)\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "# filter out stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = [w for w in stripped if not w in stop_words]\n",
    "\n",
    "bad_chars = [';', ':', '!', \"*\", '%','#','@','←','→','∞','“','”','’','=','>','.','—'] \n",
    " \n",
    "# remove bad_chars  \n",
    "test_string = filter(lambda i: i not in bad_chars, words)\n",
    "\n",
    "\n",
    "d11= list(filter(None,test_string))\n",
    "#print(w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "filename = 'documents/document_12.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "#print (text)\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "# filter out stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = [w for w in stripped if not w in stop_words]\n",
    "\n",
    "bad_chars = [';', ':', '!', \"*\", '%','#','@','←','→','∞','“','”','’','=','>','.','—'] \n",
    " \n",
    "# remove bad_chars  \n",
    "test_string = filter(lambda i: i not in bad_chars, words)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "d12 = list(filter(None,test_string))\n",
    "#print(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "filename = 'documents/document_13.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "#print (text)\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "# filter out stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = [w for w in stripped if not w in stop_words]\n",
    "\n",
    "bad_chars = [';', ':', '!', \"*\", '%','#','@','←','→','∞','“','”','’','=','>','.','—'] \n",
    " \n",
    "# remove bad_chars  \n",
    "test_string = filter(lambda i: i not in bad_chars, words)\n",
    "\n",
    "\n",
    "d13= list(filter(None,test_string))\n",
    "#print(w)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "filename = 'documents/document_14.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "#print (text)\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "# filter out stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = [w for w in stripped if not w in stop_words]\n",
    "\n",
    "bad_chars = [';', ':', '!', \"*\", '%','#','@','←','→','∞','“','”','’','=','>','.','—'] \n",
    " \n",
    "# remove bad_chars  \n",
    "test_string = filter(lambda i: i not in bad_chars, words)\n",
    "\n",
    "d14= list(filter(None,test_string))\n",
    "#print(w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "################15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "filename = 'documents/document_15.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "#print (text)\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "# filter out stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = [w for w in stripped if not w in stop_words]\n",
    "\n",
    "bad_chars = [';', ':', '!', \"*\", '%','#','@','←','→','∞','“','”','’','=','>','.','—'] \n",
    " \n",
    "# remove bad_chars  \n",
    "test_string = filter(lambda i: i not in bad_chars, words)\n",
    "\n",
    "d15= list(filter(None,test_string))\n",
    "#print(w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "filename = 'documents/document_16.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "#print (text)\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "# filter out stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = [w for w in stripped if not w in stop_words]\n",
    "\n",
    "bad_chars = [';', ':', '!', \"*\", '%','#','@','←','→','∞','“','”','’','=','>','.','—'] \n",
    " \n",
    "# remove bad_chars  \n",
    "test_string = filter(lambda i: i not in bad_chars, words)\n",
    "\n",
    "d16= list(filter(None,test_string))\n",
    "#print(w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "################17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "filename = 'documents/document_17.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "#print (text)\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "# filter out stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = [w for w in stripped if not w in stop_words]\n",
    "\n",
    "bad_chars = [';', ':', '!', \"*\", '%','#','@','←','→','∞','“','”','’','=','>','.','—'] \n",
    " \n",
    "# remove bad_chars  \n",
    "test_string = filter(lambda i: i not in bad_chars, words)\n",
    "\n",
    "d17= list(filter(None,test_string))\n",
    "#print(w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "################18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "filename = 'documents/document_18.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "#print (text)\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "# filter out stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = [w for w in stripped if not w in stop_words]\n",
    "\n",
    "bad_chars = [';', ':', '!', \"*\", '%','#','@','←','→','∞','“','”','’','=','>','.','—'] \n",
    " \n",
    "# remove bad_chars  \n",
    "test_string = filter(lambda i: i not in bad_chars, words)\n",
    "\n",
    "d18= list(filter(None,test_string))\n",
    "#print(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "################19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "filename = 'documents/document_19.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "#print (text)\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "# filter out stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = [w for w in stripped if not w in stop_words]\n",
    "\n",
    "bad_chars = [';', ':', '!', \"*\", '%','#','@','←','→','∞','“','”','’','=','>','.','—'] \n",
    " \n",
    "# remove bad_chars  \n",
    "test_string = filter(lambda i: i not in bad_chars, words)\n",
    "\n",
    "\n",
    "\n",
    "d19= list(filter(None,test_string))\n",
    "#print(w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "################20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "filename = 'documents/document_20.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "#print (text)\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "# filter out stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = [w for w in stripped if not w in stop_words]\n",
    "\n",
    "bad_chars = [';', ':', '!', \"*\", '%','#','@','←','→','∞','“','”','’','=','>','.','—'] \n",
    " \n",
    "# remove bad_chars  \n",
    "test_string = filter(lambda i: i not in bad_chars, words)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "d20= list(filter(None,test_string))\n",
    "#print(w)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "text= \"tennis match\"\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "# filter out stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = [w for w in stripped if not w in stop_words]\n",
    "\n",
    "bad_chars = [';', ':', '!', \"*\", '%','#','@','←','→','∞','“','”','’','=','>','.','—'] \n",
    " \n",
    "# remove bad_chars  \n",
    "test_string = filter(lambda i: i not in bad_chars, words)\n",
    "\n",
    "d21= list(filter(None,test_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"88 thousand people!\"\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "# filter out stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = [w for w in stripped if not w in stop_words]\n",
    "\n",
    "bad_chars = [';', ':', '!', \"*\", '%','#','@','←','→','∞','“','”','’','=','>','.','—'] \n",
    " \n",
    "# remove bad_chars  \n",
    "test_string = filter(lambda i: i not in bad_chars, words)\n",
    "\n",
    "d22= list(filter(None,test_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "text= \"the plastic container; see <img src='drawing.jpg' alt=''>\"\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# print (tokens)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "\n",
    "# # remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "\n",
    "# filter out stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = [w for w in stripped if not w in stop_words]\n",
    "\n",
    "bad_chars = [';', ':', '!', \"*\", '%','#','@','←','→','∞','“','”','’','=','>','.','—'] \n",
    " \n",
    "# remove bad_chars  \n",
    "test_string = filter(lambda i: i not in bad_chars, words)\n",
    "\n",
    "d23= list(filter(None,test_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(d1,d2,d3,d4,d5,d6,d7,d8,d9,d10,d11,d12,d13,d14,d15,d16,d17,d18,d19,d20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Union(d1,d2,d3,d4,d5,d6,d7,d8,d9,d10,d11,d12,d13,d14,d15,d16,d17,d18,d19,d20,d21,d22,d23): \n",
    "    final_list = list(set().union(d1,d2,d3,d4,d5,d6,d7,d8,d9,d10,d11,d12,d13,d14,d15,d16,d17,d18,d19,d20,d21,d22,d23)) \n",
    "    return final_list \n",
    "\n",
    "f=(Union(d1,d2,d3,d4,d5,d6,d7,d8,d9,d10,d11,d12,d13,d14,d15,d16,d17,d18,d19,d20,d21,d22,d23))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_1 = dict.fromkeys(f, 0) \n",
    "d_2= dict.fromkeys(f, 0)\n",
    "d_3 = dict.fromkeys(f, 0) \n",
    "d_4= dict.fromkeys(f, 0)\n",
    "d_5 = dict.fromkeys(f, 0) \n",
    "d_6= dict.fromkeys(f, 0)\n",
    "d_7 = dict.fromkeys(f, 0) \n",
    "d_8= dict.fromkeys(f, 0)\n",
    "d_9 = dict.fromkeys(f, 0) \n",
    "d_10= dict.fromkeys(f, 0)\n",
    "d_11 = dict.fromkeys(f, 0) \n",
    "d_12= dict.fromkeys(f, 0)\n",
    "d_13 = dict.fromkeys(f, 0) \n",
    "d_14= dict.fromkeys(f, 0)\n",
    "d_15 = dict.fromkeys(f, 0) \n",
    "d_16= dict.fromkeys(f, 0)\n",
    "d_17 = dict.fromkeys(f, 0) \n",
    "d_18= dict.fromkeys(f, 0)\n",
    "d_19 = dict.fromkeys(f, 0) \n",
    "d_20= dict.fromkeys(f, 0)\n",
    "d_21= dict.fromkeys(f, 0)\n",
    "d_22= dict.fromkeys(f, 0)\n",
    "d_23= dict.fromkeys(f, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in d1:\n",
    "    d_1[word]+=1\n",
    "    \n",
    "for word in d2:\n",
    "    d_2[word]+=1\n",
    "    \n",
    "for word in d3:\n",
    "    d_3[word]+=1\n",
    "    \n",
    "for word in d4:\n",
    "    d_4[word]+=1\n",
    "    \n",
    "for word in d5:\n",
    "    d_5[word]+=1\n",
    "    \n",
    "for word in d6:\n",
    "    d_6[word]+=1\n",
    "    \n",
    "for word in d7:\n",
    "    d_7[word]+=1\n",
    "    \n",
    "for word in d8:\n",
    "    d_8[word]+=1\n",
    "    \n",
    "for word in d9:\n",
    "    d_9[word]+=1\n",
    "    \n",
    "for word in d10:\n",
    "    d_4[word]+=1\n",
    "    \n",
    "for word in d11:\n",
    "    d_11[word]+=1\n",
    "    \n",
    "for word in d12:\n",
    "    d_12[word]+=1\n",
    "    \n",
    "for word in d13:\n",
    "    d_13[word]+=1\n",
    "    \n",
    "for word in d14:\n",
    "    d_14[word]+=1\n",
    "    \n",
    "for word in d15:\n",
    "    d_15[word]+=1\n",
    "    \n",
    "for word in d16:\n",
    "    d_16[word]+=1\n",
    "    \n",
    "for word in d17:\n",
    "    d_17[word]+=1\n",
    "    \n",
    "for word in d18:\n",
    "    d_18[word]+=1\n",
    "    \n",
    "for word in d19:\n",
    "    d_19[word]+=1\n",
    "    \n",
    "for word in d20:\n",
    "    d_20[word]+=1\n",
    "    \n",
    "for word in d21:\n",
    "    d_21[word]+=1\n",
    "    \n",
    "for word in d22:\n",
    "    d_22[word]+=1\n",
    "\n",
    "for word in d23:\n",
    "    d_23[word]+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>01oct55</th>\n",
       "      <th>02</th>\n",
       "      <th>028</th>\n",
       "      <th>02apr56</th>\n",
       "      <th>02may56</th>\n",
       "      <th>03</th>\n",
       "      <th>03dec55</th>\n",
       "      <th>03mar56</th>\n",
       "      <th>03sep55</th>\n",
       "      <th>...</th>\n",
       "      <th>–</th>\n",
       "      <th>—founded</th>\n",
       "      <th>—king</th>\n",
       "      <th>—silence</th>\n",
       "      <th>—were</th>\n",
       "      <th>€200000</th>\n",
       "      <th>−14</th>\n",
       "      <th>−892</th>\n",
       "      <th>번</th>\n",
       "      <th>호</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23 rows × 11626 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  01oct55  02  028  02apr56  02may56  03  03dec55  03mar56  03sep55  \\\n",
       "0    0        0   0    0        0        0   0        0        0        0   \n",
       "1    0        0   0    0        0        0   0        0        0        0   \n",
       "2    1        0   0    0        0        0   0        0        0        0   \n",
       "3    0        0   0    0        0        0   0        0        0        0   \n",
       "4   17        0   0    0        0        0   0        0        0        0   \n",
       "5    0        0   0    0        0        0   0        0        0        0   \n",
       "6    0        0   0    0        0        0   0        0        0        0   \n",
       "7    1        0   0    0        0        0   0        0        0        0   \n",
       "8    0        0   0    0        0        0   0        0        0        0   \n",
       "9    0        0   0    0        0        0   0        0        0        0   \n",
       "10  11        0   0    0        0        0   0        0        0        0   \n",
       "11   8        0   0    0        0        0   0        0        0        0   \n",
       "12   0        0   0    0        0        0   0        0        0        0   \n",
       "13   0        1   0    0        1        1   0        1        1        1   \n",
       "14   0        0   2    1        0        0   1        0        0        0   \n",
       "15   0        0   0    0        0        0   0        0        0        0   \n",
       "16   0        0   0    0        0        0   0        0        0        0   \n",
       "17   0        0   0    0        0        0   0        0        0        0   \n",
       "18   0        0   0    0        0        0   0        0        0        0   \n",
       "19   0        0   0    0        0        0   0        0        0        0   \n",
       "20   0        0   0    0        0        0   0        0        0        0   \n",
       "21   0        0   0    0        0        0   0        0        0        0   \n",
       "22   0        0   0    0        0        0   0        0        0        0   \n",
       "\n",
       "    ...   –  —founded  —king  —silence  —were  €200000  −14  −892  번  호  \n",
       "0   ...   1         0      0         0      0        0    0     0  0  0  \n",
       "1   ...   6         0      0         0      0        0    0     1  0  0  \n",
       "2   ...   1         0      0         0      0        0    0     0  0  0  \n",
       "3   ...   0         0      0         0      0        0    0     0  0  0  \n",
       "4   ...  55         0      0         0      0        1    0     0  0  0  \n",
       "5   ...   0         0      0         0      0        0    0     0  0  0  \n",
       "6   ...   0         0      0         0      0        0    0     0  0  0  \n",
       "7   ...   1         0      0         0      0        0    0     0  1  1  \n",
       "8   ...   1         0      0         0      0        0    0     0  0  0  \n",
       "9   ...   0         0      0         0      0        0    0     0  0  0  \n",
       "10  ...   0         0      0         0      0        0    0     0  0  0  \n",
       "11  ...   5         0      0         0      0        0    0     0  0  0  \n",
       "12  ...   0         0      0         0      0        0    0     0  0  0  \n",
       "13  ...   0         0      0         0      0        0    0     0  0  0  \n",
       "14  ...   7         0      0         0      0        0    0     0  0  0  \n",
       "15  ...   1         0      0         0      0        0    0     0  0  0  \n",
       "16  ...   2         0      0         0      0        0    0     0  0  0  \n",
       "17  ...   0         0      0         0      0        0    0     0  0  0  \n",
       "18  ...  13         0      0         1      0        0    1     0  0  0  \n",
       "19  ...   1         1      1         0      1        0    0     0  0  0  \n",
       "20  ...   0         0      0         0      0        0    0     0  0  0  \n",
       "21  ...   0         0      0         0      0        0    0     0  0  0  \n",
       "22  ...   0         0      0         0      0        0    0     0  0  0  \n",
       "\n",
       "[23 rows x 11626 columns]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([d_1,d_2,d_3,d_4,d_5,d_6,d_7,d_8,d_9,d_10,d_11,d_12,d_13,d_14,d_15,d_16,d_17,d_18,d_19,d_20,d_21,d_22,d_23])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compute Term Frequency:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF (Term Frequency)= (Number of time the word occurs in the text) / (Total number of words in text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF(d_, d):\n",
    "    tfDict = {}\n",
    "    bowCount = len(d)\n",
    "    for word, count in d_.items():\n",
    "        tfDict[word] = count/float(bowCount)\n",
    "    return tfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfd_1 = computeTF(d_1, d1)\n",
    "tfd_2 = computeTF(d_2, d2)\n",
    "tfd_3 = computeTF(d_3, d3)\n",
    "tfd_4 = computeTF(d_4, d4)\n",
    "tfd_5 = computeTF(d_5, d5)\n",
    "tfd_6 = computeTF(d_6, d6)\n",
    "tfd_7 = computeTF(d_7, d7)\n",
    "tfd_8 = computeTF(d_8, d8)\n",
    "tfd_9 = computeTF(d_9, d9)\n",
    "tfd_10 = computeTF(d_10, d10)\n",
    "tfd_11 = computeTF(d_11, d11)\n",
    "tfd_12 = computeTF(d_12, d12)\n",
    "tfd_13 = computeTF(d_13, d13)\n",
    "tfd_14 = computeTF(d_14, d14)\n",
    "tfd_15 = computeTF(d_15, d15)\n",
    "tfd_16 = computeTF(d_16, d16)\n",
    "tfd_17 = computeTF(d_17, d17)\n",
    "tfd_18 = computeTF(d_18, d18)\n",
    "tfd_19 = computeTF(d_19, d19)\n",
    "tfd_20 = computeTF(d_20, d20)\n",
    "tfd_21 = computeTF(d_21, d21)\n",
    "tfd_22 = computeTF(d_22, d22)\n",
    "tfd_23 = computeTF(d_20, d23)\n",
    "\n",
    "# tfBowB = computeTF(wordDictB, bowB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compte Inverse Document Frequency:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IDF (Inverse Document Frequency)= (Total number of documents / Number of documents with word t in it)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeIDF(docList):\n",
    "    import math\n",
    "    idfDict = {}\n",
    "    N = len(docList)\n",
    "    \n",
    "    idfDict = dict.fromkeys(docList[0].keys(), 0)\n",
    "    for doc in docList:\n",
    "        for word, val in doc.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "    \n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log10(N / float(val))\n",
    "        \n",
    "    return idfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs = computeIDF([d_1, d_2,d_3,d_4,d_5,d_6, d_7,d_8,d_9,d_10,d_11, d_12,d_13,d_14,d_15,d_16, d_17,d_18,d_19,d_20,d_21,d_22,d_23])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# computeTFIDF:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF = TF * IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTFIDF(tfd_, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfd_.items():\n",
    "        tfidf[word] = val*idfs[word]\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfd_1 = computeTFIDF(tfd_1, idfs)\n",
    "tfidfd_2 = computeTFIDF(tfd_2, idfs)\n",
    "tfidfd_3 = computeTFIDF(tfd_3, idfs)\n",
    "tfidfd_4 = computeTFIDF(tfd_4, idfs)\n",
    "tfidfd_5 = computeTFIDF(tfd_5, idfs)\n",
    "tfidfd_6 = computeTFIDF(tfd_6, idfs)\n",
    "tfidfd_7 = computeTFIDF(tfd_7, idfs)\n",
    "tfidfd_8 = computeTFIDF(tfd_8, idfs)\n",
    "tfidfd_9 = computeTFIDF(tfd_9, idfs)\n",
    "tfidfd_10 = computeTFIDF(tfd_10, idfs)\n",
    "tfidfd_11 = computeTFIDF(tfd_11, idfs)\n",
    "tfidfd_12 = computeTFIDF(tfd_12, idfs)\n",
    "tfidfd_13 = computeTFIDF(tfd_13, idfs)\n",
    "tfidfd_14 = computeTFIDF(tfd_14, idfs)\n",
    "tfidfd_15 = computeTFIDF(tfd_15, idfs)\n",
    "tfidfd_16 = computeTFIDF(tfd_16, idfs)\n",
    "tfidfd_17 = computeTFIDF(tfd_17, idfs)\n",
    "tfidfd_18 = computeTFIDF(tfd_18, idfs)\n",
    "tfidfd_19 = computeTFIDF(tfd_19, idfs)\n",
    "tfidfd_20 = computeTFIDF(tfd_20, idfs)\n",
    "tfidfd_21 = computeTFIDF(tfd_21, idfs)\n",
    "tfidfd_22 = computeTFIDF(tfd_22, idfs)\n",
    "tfidfd_23 = computeTFIDF(tfd_23, idfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>01oct55</th>\n",
       "      <th>02</th>\n",
       "      <th>028</th>\n",
       "      <th>02apr56</th>\n",
       "      <th>02may56</th>\n",
       "      <th>03</th>\n",
       "      <th>03dec55</th>\n",
       "      <th>03mar56</th>\n",
       "      <th>03sep55</th>\n",
       "      <th>...</th>\n",
       "      <th>–</th>\n",
       "      <th>—founded</th>\n",
       "      <th>—king</th>\n",
       "      <th>—silence</th>\n",
       "      <th>—were</th>\n",
       "      <th>€200000</th>\n",
       "      <th>−14</th>\n",
       "      <th>−892</th>\n",
       "      <th>번</th>\n",
       "      <th>호</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001278</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003726</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.005170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.006686</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001782</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001288</td>\n",
       "      <td>0.001288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001288</td>\n",
       "      <td>0.001288</td>\n",
       "      <td>0.001288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047091</td>\n",
       "      <td>0.226955</td>\n",
       "      <td>0.226955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.226955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23 rows × 11626 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0   01oct55        02       028   02apr56   02may56        03  \\\n",
       "0   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2   0.002999  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4   0.002701  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "6   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "7   0.000174  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "8   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "9   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "10  0.005170  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "11  0.006686  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "12  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "13  0.000000  0.001288  0.000000  0.000000  0.001288  0.001288  0.000000   \n",
       "14  0.000000  0.000000  0.000848  0.000424  0.000000  0.000000  0.000424   \n",
       "15  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "16  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "17  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "18  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "19  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "20  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "21  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "22  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "     03dec55   03mar56   03sep55  ...         –  —founded     —king  —silence  \\\n",
       "0   0.000000  0.000000  0.000000  ...  0.000139  0.000000  0.000000  0.000000   \n",
       "1   0.000000  0.000000  0.000000  ...  0.000986  0.000000  0.000000  0.000000   \n",
       "2   0.000000  0.000000  0.000000  ...  0.001278  0.000000  0.000000  0.000000   \n",
       "3   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "4   0.000000  0.000000  0.000000  ...  0.003726  0.000000  0.000000  0.000000   \n",
       "5   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "6   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "7   0.000000  0.000000  0.000000  ...  0.000074  0.000000  0.000000  0.000000   \n",
       "8   0.000000  0.000000  0.000000  ...  0.001385  0.000000  0.000000  0.000000   \n",
       "9   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "10  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "11  0.000000  0.000000  0.000000  ...  0.001782  0.000000  0.000000  0.000000   \n",
       "12  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "13  0.001288  0.001288  0.001288  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "14  0.000000  0.000000  0.000000  ...  0.000616  0.000000  0.000000  0.000000   \n",
       "15  0.000000  0.000000  0.000000  ...  0.000274  0.000000  0.000000  0.000000   \n",
       "16  0.000000  0.000000  0.000000  ...  0.000744  0.000000  0.000000  0.000000   \n",
       "17  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "18  0.000000  0.000000  0.000000  ...  0.000411  0.000000  0.000000  0.000153   \n",
       "19  0.000000  0.000000  0.000000  ...  0.000031  0.000151  0.000151  0.000000   \n",
       "20  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "21  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "22  0.000000  0.000000  0.000000  ...  0.047091  0.226955  0.226955  0.000000   \n",
       "\n",
       "       —were   €200000       −14      −892         번         호  \n",
       "0   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1   0.000000  0.000000  0.000000  0.000792  0.000000  0.000000  \n",
       "2   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "4   0.000000  0.000326  0.000000  0.000000  0.000000  0.000000  \n",
       "5   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "6   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "7   0.000000  0.000000  0.000000  0.000000  0.000357  0.000357  \n",
       "8   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "9   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "10  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "11  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "12  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "13  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "14  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "15  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "16  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "17  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "18  0.000000  0.000000  0.000153  0.000000  0.000000  0.000000  \n",
       "19  0.000151  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "20  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "21  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "22  0.226955  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[23 rows x 11626 columns]"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "result1=pd.DataFrame([tfidfd_1, tfidfd_2,tfidfd_3,tfidfd_4,tfidfd_5,tfidfd_6,tfidfd_7,tfidfd_8,tfidfd_9,tfidfd_10,\n",
    "             tfidfd_11, tfidfd_12,tfidfd_13,tfidfd_14,tfidfd_15,tfidfd_16,tfidfd_17,tfidfd_18,tfidfd_19,tfidfd_20,\n",
    "             tfidfd_21,tfidfd_22,tfidfd_23])\n",
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(r'result1.txt', result1.values, fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
